<?xml version="1.0" encoding="utf-8"?>

<feed xmlns="http://www.w3.org/2005/Atom" >
  <generator uri="https://jekyllrb.com/" version="3.7.4">Jekyll</generator>
  <link href="/tag/apple/feed.xml" rel="self" type="application/atom+xml" />
  <link href="/" rel="alternate" type="text/html" />
  <updated>2020-03-16T21:37:12-04:00</updated>
  <id>/tag/apple/feed.xml</id>

  
  
  

  
    <title type="html">dippnerd | </title>
  

  
    <subtitle>things to nerd out about</subtitle>
  

  

  
    
      
    
  

  
  

  
    <entry>
      <title type="html">Catalyst - the future of Mac apps?</title>
      <link href="/mac-catalyst" rel="alternate" type="text/html" title="Catalyst - the future of Mac apps?" />
      <published>2020-02-05T20:27:06-05:00</published>
      <updated>2020-02-05T20:27:06-05:00</updated>
      <id>/mac-catalyst</id>
      <content type="html" xml:base="/mac-catalyst">&lt;p&gt;Back in June 2019 at WWDC Apple announced Mac Catalyst, a new way to build apps that share one common codebase that can run across iPadOS, iOS and macOS. Very shortly after this announcement, they also announced the new SwiftUI, an easy way to create apps for Mac, iPad, iPhone, etc. Immediately people were joking about how Apple announced and promptly killed Catalyst in the same presentation, but I don’t think this is quite the case.&lt;/p&gt;

&lt;p&gt;First, a little deeper dive into Catalyst. What this was pitched as is a way to write an iOS/iPadOS app, and with little to no effort (it’s literally as simple as checking a box!) you can magically add support for macOS. We saw some demo apps of this in iOS 12 the year before (Stocks, Voice Recorder, Home) that were less than ideal, but technically got the job done. Where these apps didn’t exist before on macOS, suddenly they did.&lt;/p&gt;

&lt;p&gt;Unfortunately there’s a lot of small details that weren’t quite so painless. Most apps won’t be as simple as just checking a box, you’ll likely need to separate out some code that differentiates between platforms for both UI appeal, but also functionality (or lack there of in some cases) that differs. Those problems aside, it is still an impressive feat to consider how much &lt;em&gt;less&lt;/em&gt; effort it takes to build an app with Catalyst compared to building two completely separate apps.&lt;/p&gt;

&lt;p&gt;Heading back to SwiftUI, the thing that gets easily overlooked in this debate of SwiftUI vs Catalyst is that SwiftUI is still only one piece of the puzzle. It’s also a piece that is compatible with Catalyst, whose roots go far deeper than just the UI. SwiftUI is a great way to “declare” your UI, but it doesn’t do much else, it’s not meant to. Catalyst, however, is responsible for not only UI, but also a lot of other underlying frameworks and APIs that aren’t necessarily exposed to macOS apps the same way.&lt;/p&gt;

&lt;p&gt;When writing an app for iOS, then learning macOS, it is quick to see they both share some things, and act wildly different with others. If you want, you can write separate iOS and macOS apps using SwiftUI and the respective frameworks for each platform, but ultimately you’ll be still doing twice the work. When using SwiftUI &lt;em&gt;with&lt;/em&gt; Catalyst, you can share a common codebase. It’s easy to miss the difference, but it is there.&lt;/p&gt;

&lt;p&gt;Traditionally, macOS apps have been built using a framework called AppKit, while iOS apps use UIKit. They are very uniquely separate frameworks for different tasks, but this is why SwiftUI alone does not mean you get two apps from one codebase. Catalyst, in a sense, is a sort of “translator” of your code, to allow it to run on macOS. Behind the scenes, while I’m not entirely sure what Apple does to make this work, I suspect it’s an effort that is not being replaced immediately with SwiftUI.&lt;/p&gt;

&lt;p&gt;I believe Catalyst is more of a long-term strategy at Apple to not only share apps across platforms, but to also bring the platforms themselves closer together. There are still so many thing macOS is lacking that iOS/iPadOS have (or at least can do better). The same could be said on the reverse. The tricky part is figuring out where to draw lines in the sand for any of this. Catalyst feels like Apple saying “we prefer the iOS way of building apps, so if you want iOS functionality, this is the way”.&lt;/p&gt;

&lt;p&gt;While we don’t have 100% feature parity with Catalyst yet, it is still young. I think what we’ll see down the road is the expansion of features like Siri Shortcuts or the Shortcuts app, but only available to Catalyst apps. If you build an app with SwiftUI but via AppKit as a standalone app, you’ll not only have to maintain a separate codebase from your iOS app, but you’ll also miss out on features that Catalyst provides from iOS. This makes sense in a lot of ways, as it means users who want AppKit can still use it, but over time it will stop getting new features and eventually even get dropped altogether (probably not for a while though).&lt;/p&gt;

&lt;p&gt;Speaking of Siri Shortcuts, this would be the easy way to avoid having to add support for Shortcuts to legacy apps. Only Catalyst apps get these features, AppKit gets left behind. Sure, developers can still make AppKit apps, and will make great ones I’m sure, but to get that “iOS on Mac” experience, it’ll have to be Catalyst.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;tl;dr&lt;/strong&gt;: Catalyst is way more than just UI, while SwiftUI is basically just UI (hence the name). To get a true cross-platform, one-codebase end result, Catalyst is a way safer bet than SwiftUI+AppKit/UIKit. Expect features to be exclusive to Catalyst instead of AppKit over time.&lt;/p&gt;</content>

      
      
      
      
      

      <author>
          <name>Aaron Dippner</name>
        
        
      </author>

      

      
        <category term="apple" />
      
        <category term="mac" />
      
        <category term="catalyst" />
      
        <category term="swift" />
      
        <category term="swiftui" />
      

      
        <summary type="html">Back in June 2019 at WWDC Apple announced Mac Catalyst, a new way to build apps that share one common codebase that can run across iPadOS, iOS and macOS. Very shortly after this announcement, they also announced the new SwiftUI, an easy way to create apps for Mac, iPad, iPhone, etc. Immediately people were joking about how Apple announced and promptly killed Catalyst in the same presentation, but I don’t think this is quite the case.</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">iPod, HomePod, iPad, HomePad?</title>
      <link href="/homepad" rel="alternate" type="text/html" title="iPod, HomePod, iPad, HomePad?" />
      <published>2019-08-20T13:12:20-04:00</published>
      <updated>2019-08-20T13:12:20-04:00</updated>
      <id>/homepad</id>
      <content type="html" xml:base="/homepad">&lt;p&gt;There has been a growing market for voice assistant devices in the past few years. These range from small, $30 circular devices that can plug into other speakers, to fully-integrated speakers, evolving into ones that include screens even.&lt;/p&gt;

&lt;p&gt;Some recent examples include Amazon’s Echo Show, a device that includes both the Alexa assistant as well as screen to display song lyrics, recipes, etc. Google’s take on this is the Google Home Hub, similar build with a focus on voice commands that give visual results.&lt;/p&gt;

&lt;p&gt;Apple’s only foray into this space of stand-alone, dedicated voice assistant hardware has been the HomePod. It’s often touted as the “Siri Speaker” even though Apple insists it’s more of a music speaker that happens to have Siri for an interface. It comes with plenty of useful features outside of music though, ranging from multiple timers to being able to get calendar info, weather and other things Siri does on the phone already.&lt;/p&gt;

&lt;p&gt;Apple is notoriously silent about future products, but people often speculate whether they will try to compete with the likes of Echo Show or Google Home Hub by making a similar assistant-focused device with a screen. The common argument against this is that we already have such a device, the iPad. It has Siri, can do many of the same features as HomePod already, and serves as a multi-purpose device instead of being stuck in one room with very narrow features.&lt;/p&gt;

&lt;p&gt;While I agree that the iPad does fill many of these gaps already, there are many reasons a “HomePad” device could be appealing (for the right price of course). For starters, Siri just doesn’t work the same on the iPad as the voice assistants on these other screen-focused devices. Siri can present some basic info hands-free, but often requires the user to authenticate to do more. This is good for things like reading messages and private content like notes, but for just bringing up a basic recipe or showing song lyrics, unlocking shouldn’t be needed. The interfaces for those functions also tend to require a few taps to get where you’re going as well, so Siri would need a revamped UI to better compete in this space.&lt;/p&gt;

&lt;p&gt;With a dedicated “HomePad”, it could remove the “i” focus of the iPad, being individual-based instead of multi-user. Instead, this device could focus on things that don’t necessary need security authentication, but allow restrictions for the user in terms of what content can be accessed. Similar to how HomePod has “personal requests” which allows the user to access calendar events and such, this feature could exist on “HomePad” as well, and have the ability to disable it just the same.&lt;/p&gt;

&lt;p&gt;The main goal would be to have an assistant in places where your hands are often dirty or otherwise inaccessible, particularly the kitchen. Being able to play videos, music (with lyrics), show recipes and other basic web site results would make this a lot more useful than Siri on the iPad currently is. On the flip side, instead of making dedicated hardware, opening the iPad to do all of these things could be an easy gateway into homes that have iPads everywhere already. Sure, they aren’t buying new hardware, but they also aren’t buying the competitor’s assistant just to get the same job done.&lt;/p&gt;</content>

      
      
      
      
      

      <author>
          <name>Aaron Dippner</name>
        
        
      </author>

      

      
        <category term="apple" />
      
        <category term="homepod" />
      
        <category term="homepad" />
      
        <category term="ipad" />
      
        <category term="siri" />
      
        <category term="google" />
      
        <category term="amazon" />
      

      
        <summary type="html">There has been a growing market for voice assistant devices in the past few years. These range from small, $30 circular devices that can plug into other speakers, to fully-integrated speakers, evolving into ones that include screens even.</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">SwiftUI - Using Timer for UI refreshes</title>
      <link href="/swiftui-timer-ui-refresh" rel="alternate" type="text/html" title="SwiftUI - Using Timer for UI refreshes" />
      <published>2019-07-25T14:16:26-04:00</published>
      <updated>2019-07-25T14:16:26-04:00</updated>
      <id>/swiftui-timer-ui-refresh</id>
      <content type="html" xml:base="/swiftui-timer-ui-refresh">&lt;p&gt;At WWDC this year, one of Apple’s biggest announcements wasn’t a particular feature of the new OSes, but rather a new way to write UIs for your apps using Swift. This new framework, named SwiftUI, uses a declaritive syntax to easily define your UI in far fewer lines of code than before. Along with SwiftUI, Apple announced another framework, Combine, which helps with handling asynchronous events. This post won’t dive into the fundamentals of either of these, there are plenty of others out there already. Instead, this post is intended to work through some challenges I ran into when trying to upgrade my app, &lt;a href=&quot;https://itunes.apple.com/us/app/just-timers/id1453573845?ls=1&amp;amp;mt=8&quot;&gt;Just Timers&lt;/a&gt;, to use SwiftUI.&lt;/p&gt;

&lt;p&gt;When I wrote Just Timers, I used UIKit by pushing my content into a UITableView, pretty standard. A nice feature of UITableView for an app that needs the UI to constantly refresh is the ability to simply use a timer to repeat at a given interval and run a method that refreshes your table, like so:&lt;/p&gt;

&lt;div class=&quot;language-swift highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kt&quot;&gt;Timer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;scheduledTimer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;timeInterval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;selector&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;#selector(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;TimerViewController.refreshCells&lt;/span&gt;&lt;span class=&quot;kd&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;userInfo&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;nil&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;repeats&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The &lt;code class=&quot;highlighter-rouge&quot;&gt;refreshCells&lt;/code&gt; method iterates over the visible cells of the table and changes various parts of the UI depending on what values the object in that cell is in. If a value changed from paused to running, the button gets updated to reflect this; if the timer expired, the UI changes color, etc. Calling the method on a reoccuring timer is easy, but updating your UI in here can get rather complex very fast.&lt;/p&gt;

&lt;p&gt;Meanwhile, in SwiftUI, you can very easily describe your UI by breaking it into multiple views, each responsible for their own piece of the picture. You track each state inside of the given view, then when the view is updated, whatever state each piece is in gets reflected in the UI. This vastly simplifies both your UI code and keeping track of states, but it posed a new problem I wasn’t quite prepared for:  Something like &lt;code class=&quot;highlighter-rouge&quot;&gt;refreshCells&lt;/code&gt; doesn’t work the same way here. We don’t reference individual cells like UITableView, everything is just defined in the UI and changes when the state of that view changes.&lt;/p&gt;

&lt;p&gt;Enter Combine. In order to utilize Timer in a way that will allow my views to “subscribe” to it firing, we need to create a wrapper class that will house our timer. Using Combine, we make this wrapper a BindableObject and add the necessary requirements. Effectively, this class will contain our timer instance, then every time the timer fires, it will call the willChange method to let subscribers know it just fired off an event.&lt;/p&gt;
&lt;div class=&quot;language-swift highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;SwiftUI&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Combine&lt;/span&gt;

&lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;TimerWrapper&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;ObservableObject&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;objectWillChange&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;ObservableObjectPublisher&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;timer&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Timer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;
    &lt;span class=&quot;kd&quot;&gt;func&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;withTimeInterval&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;interval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Double&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;timer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;?&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;invalidate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;timer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Timer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;scheduledTimer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;withTimeInterval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;interval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;repeats&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;objectWillChange&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;send&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    
    &lt;span class=&quot;kd&quot;&gt;func&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;stop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;timer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;?&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;invalidate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We’ll need a way to reference this timer in SwiftUI, so next we go to our SceneDelegate and update scene(…willConnectTo) to create our timer instance and pass it into the root view controller as an environment object:&lt;/p&gt;
&lt;div class=&quot;language-swift highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;windowScene&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scene&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as?&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;UIWindowScene&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;window&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;UIWindow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;windowScene&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;windowScene&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;window&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rootViewController&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;UIHostingController&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;rootView&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;contentView&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;environmentObject&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;timerObject&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;environmentObject&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;timerWrapper&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;window&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;window&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;window&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;makeKeyAndVisible&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Keep in mind we created our instance of TimerWrapper and have to start it (providing an interval in seconds). This instance will remain active in SceneDelegate, and by utilizing &lt;code class=&quot;highlighter-rouge&quot;&gt;.environmentObject&lt;/code&gt; we can make this instance accessible anywhere in our code now.&lt;/p&gt;

&lt;p&gt;Now, anywhere we want our UI to update with this given interval, just add this to your view:&lt;/p&gt;
&lt;div class=&quot;language-swift highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;@EnvironmentObject&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;timerWrapper&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;TimerWrapper&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;You don’t need to do anything else with that value. By simply referencing it in your view, the publisher will automatically nofify each view that is subscribed, causing them to redraw their view due to the state change.&lt;/p&gt;

&lt;p&gt;Something to consider:  It’s easy to think &lt;em&gt;“I’ll just put this on my root view and everything will update!”&lt;/em&gt; Technically this is true, but in my experience it causes buttons and other interactions to become difficult to use. Instead, consider the views that will need updated specifically. In my case, the string that displays my timer’s current value is the only thing that needs updated by this timer. By putting that into its own view, you not only simplify code by separating it, but you can also reference the timer wrapper in this view only to prevent the entire UI getting bogged down.&lt;/p&gt;

&lt;p&gt;I hope this helps anyone out trying to something similar. I didn’t come to all of this on my own, credit goes to &lt;a href=&quot;https://stackoverflow.com/a/56905649/9012764&quot;&gt;this Stack Overflow answer&lt;/a&gt; and &lt;a href=&quot;https://www.reddit.com/r/iOSProgramming/comments/cf219v/force_swiftui_list_contents_to_update/eu6rk28/&quot;&gt;this response&lt;/a&gt; to my problem on Reddit.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;Update 21 February 2020:&lt;/em&gt;&lt;/strong&gt; &lt;em&gt;SwiftUI and Combine had some growing pains through the beta periods and have changed along the way. The code snippets above have been updated with current changes, like ‘willChange’ becoming ‘objectWillChange’.&lt;/em&gt;&lt;/p&gt;</content>

      
      
      
      
      

      <author>
          <name>Aaron Dippner</name>
        
        
      </author>

      

      
        <category term="apple" />
      
        <category term="swiftui" />
      
        <category term="timers" />
      

      
        <summary type="html">At WWDC this year, one of Apple’s biggest announcements wasn’t a particular feature of the new OSes, but rather a new way to write UIs for your apps using Swift. This new framework, named SwiftUI, uses a declaritive syntax to easily define your UI in far fewer lines of code than before. Along with SwiftUI, Apple announced another framework, Combine, which helps with handling asynchronous events. This post won’t dive into the fundamentals of either of these, there are plenty of others out there already. Instead, this post is intended to work through some challenges I ran into when trying to upgrade my app, Just Timers, to use SwiftUI.</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">AirPods 2: Electric Boogaloo</title>
      <link href="/airpods-2-electric-boogaloo" rel="alternate" type="text/html" title="AirPods 2&amp;#58; Electric Boogaloo" />
      <published>2019-03-28T07:07:36-04:00</published>
      <updated>2019-03-28T07:07:36-04:00</updated>
      <id>/airpods-2-electric-boogaloo</id>
      <content type="html" xml:base="/airpods-2-electric-boogaloo">&lt;p&gt;Last week Apple started surprising everyone with a product refresh every day. Starting on Monday, Apple refreshed the iPad Air and Mini, Tuesday saw a refresh of the iMac lineup and finally Wednesday saw the refresh of AirPods. While every product was a bit surprising to see, for most people the AirPods refresh was the most unexpected. There had been rumors of a refresh coming, but they were always pretty vague on details and timing. After much waiting, finally Apple revealed AirPods 2: Electric Boogaloo.&lt;/p&gt;

&lt;p&gt;While some expected a complete redesign (or at least a dark color option), AirPods 2 are actually a fairly minor upgrade over the first generation. The biggest change is the added support for “Hey Siri” via the AirPods. Previously, you had to rely on double-tapping one AirPod (assuming you assigned Siri to that specific AirPod too) to summon the assistant. Now, AirPods 2 lets you simply utter “Hey Siri” into the air and the assistant will chime in. You can still assign a double-tap gesture to each AirPod, but no need for Siri for that anymore, giving room for more control.&lt;/p&gt;

&lt;p&gt;While “Hey Siri” is the biggest change, that doesn’t mean the other changes are any less welcomed. The first generation used a chip Apple called the W1, their first wireless chip, to provide some of the cutting-edge features the first generation boasted. AirPods 2 now contain what Apple calls the H1 headphone chip, though in reality it is likely more of a marketing rebranding than a completely new chip. The H1 boasts up to 2x faster switching between active devices, 1.5x faster connection time for phone calls, up to 30 percent lower gaming latency, longer talk time, and of course the “Hey Siri” functionality.&lt;/p&gt;

&lt;p&gt;One of my biggest complaints about the first generation AirPods was that, while it was nice to only have to pair them to one device and have them show up across the rest of my devices, often you would hit massive waiting periods while they switch from one device to another. Sometimes it was quick, but other times it would take longer than if I had just re-paired them manually, which could get frustrating. Some of this is simply the nature of Bluetooth, combined with the fact that some devices may be using an older Bluetooth chip or software. AirPods 2 do indeed fulfill some of their improved switching claims, but I’ve noticed this primarily relates to newer devices using Bluetooth 5.0, such as the iPhone XS and Apple Watch Series 4. When switching between the iPhone XS and my 2018 iPad (Bluetooth 4.2) the delays are mostly the same as the previous generation.&lt;/p&gt;

&lt;p&gt;Regarding the 1.5x faster connection time for phone calls, I can’t speak to this specifically for phone calls yet, but I have noticed that the connected sound seems to happen much sooner than on previous generations. In the past, you would pop them out of their case and into your ears and sometimes it would be quick, other times it might take a few seconds before you hear the tone. For the most part with AirPods 2, by the time I have the first one in my ear I already hear the sound before I get a chance to put the second in. If this is any indicator of what to expect when taking a phone call, I think it will be a huge improvement.&lt;/p&gt;

&lt;p&gt;Since I don’t play a lot of games, I can’t give real good feedback on the lower latency, but it does seem lower in general when interacting with user interfaces that provide sound feedback. The first generation weren’t terrible at this, but it was generally just noticeable enough to be annoying, so this hopefully fixes that.&lt;/p&gt;

&lt;p&gt;One of the requirements for the new AirPods was updating to the latest OS versions. I’m not positive just what changed with that, but since watchOS 5.2 was delayed a few days I did wait until then to give a proper test between the iPhone XS and Apple Watch Series 4. As mentioned above, it does seem like when switching AirPods between two Bluetooth 5.0 devices have nearly instant switching, which is a great improvement.&lt;/p&gt;

&lt;p&gt;AirPods have always been able to pair with both the phone and watch simultaneously, but generally it was shaky as to just which device would pick up tap gestures or Siri commands, which was always frustrating. It seems like the new “Hey Siri” on AirPods 2 prioritizes the phone, so that’s much appreciated (as the watch can’t do all of the same tasks as the phone). We’ll see over the longterm if this still holds up, but so far so good.&lt;/p&gt;

&lt;p&gt;Outside of the AirPods themselves, the case also got a minor update that adds support for Qi wireless charging. I didn’t opt for this case since I have no problems charging mine every day, but it does seem useful for folks looking to just set their AirPods down somewhere to let them charge.&lt;/p&gt;

&lt;p&gt;So far my only real “complaint” would be on the “Hey Siri” side of things. When you use the trigger phrase directly on the phone, you get a chime to let you know it heard you. With the AirPods there is no longer the same chime, Siri simply responds to your command, but this isn’t always immediate if she needs to fetch data from the web or something. This delay can cause you to think Siri didn’t hear you and cause you to try again, but I’ve been able to train myself to be more patient.&lt;/p&gt;

&lt;p&gt;Another interesting detail is that the phone appears to wake the screen whenever you invoke Siri, regardless of whether you cover up the mics so only AirPods would be hearing you. This seems unnecessary if the phone is on your pocket, but they may have ways to detect that too. It’s a minor detail, but one that I found a bit unexpected given the context that Siri should only display something if there is an expectation of visual feedback over audio-only.&lt;/p&gt;

&lt;p&gt;Overall I’m very pleased with this update of the AirPods. For the most part they’ve fixed all of my complaints with the last generation. The delays that still exist seem to be more at the fault of older devices, so that will likely improve as everything moves to Bluetooth 5.0+ anyway. “Hey Siri” is a hugely welcomed feature for me, as it has been the missing piece to the whole Siri ecosystem in my opinion.&lt;/p&gt;</content>

      
      
      
      
      

      <author>
          <name>Aaron Dippner</name>
        
        
      </author>

      

      
        <category term="apple" />
      
        <category term="airpods" />
      
        <category term="siri" />
      

      
        <summary type="html">Last week Apple started surprising everyone with a product refresh every day. Starting on Monday, Apple refreshed the iPad Air and Mini, Tuesday saw a refresh of the iMac lineup and finally Wednesday saw the refresh of AirPods. While every product was a bit surprising to see, for most people the AirPods refresh was the most unexpected. There had been rumors of a refresh coming, but they were always pretty vague on details and timing. After much waiting, finally Apple revealed AirPods 2: Electric Boogaloo.</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">Siri Shortcuts</title>
      <link href="/siri-shortcuts" rel="alternate" type="text/html" title="Siri Shortcuts" />
      <published>2018-06-08T17:10:24-04:00</published>
      <updated>2018-06-08T17:10:24-04:00</updated>
      <id>/siri-shortcuts</id>
      <content type="html" xml:base="/siri-shortcuts">&lt;p&gt;At WWDC this week, Apple announced a huge milestone for Siri: Siri Shortcuts. Back when Apple acquired the company behind Workflow, a powerful automation tool for iOS, there was much speculation on just what would happen. Many feared it would disappear, never to be seen again, but over time we still saw bug fix updates come to the Workflow app. At WWDC they showed off Siri Shortcuts, and an app called Shorcuts that will coincide with this. It is very clear that this Shortcuts app is the result of the Workflow acquisition. The layout is almost identical, but the key difference this time around is that it is much more deeply integrated with iOS.&lt;/p&gt;

&lt;p&gt;The Shortcuts app itself would be pretty handy in general, you’ll be able to build Automator-style “Shortcuts” that can trigger actions throughout the OS. Apple showed that third-parties will also be able to integrate with this, so the benefits begin to snowball into something very interesting. Apple didn’t stop there, however. Combine all of this with the “Siri” side of things:  Shortcuts will be able to trigger using custom voice phrases that the user can assign for Siri. Telling Siri “laundry time” could kick off a custom Shortcut that the user created, for example. The icing on the cake with all of this is that, beyond just voice, Siri will recognize patterns in usage for these Shortcuts and offer recommendations for them throughout the OS.&lt;/p&gt;

&lt;p&gt;Some examples of Siri recommendations include Spotlight/Siri search, where the user can pull down on the home screen and it will present some suggested shortcuts based on relevant context (time, location, etc). Running late for a meeting? It may offer to text your boss. Going to the gym? It may recognize a gym Shortcut you setup to start a workout and listen to a podcast.&lt;/p&gt;

&lt;p&gt;These recommendations can also be helped along by third-party apps. These apps can “donate” Siri relevant data for it to analyze and find patterns with. Apple offers various ways to “nudge” Siri in the right direction if you know you want the user to see this information within certain times, events, etc, but overall it sounds like it should be pretty capable of learning and offering useful suggestions.&lt;/p&gt;

&lt;p&gt;Some other ways these Shortcuts will come up include the lock screen and the Siri watch face for Apple watch. This is particularly exciting, as it will be possible for many tasks to be carried off in the background, the user simply needs to invoke it from the watch face or trigger phrase.&lt;/p&gt;

&lt;p&gt;While some of these details are still unclear, these Siri Shortcuts offer a huge leap in capabilities for Siri. What used to be a fairly limited set of SiriKit domains will not be opened pretty wide for third-parties to do as they please. It hasn’t been made clear if apps will be able to request additional information, such as asking the user for input without opening the app, but if this isn’t available at launch, surely it won’t be far behind.&lt;/p&gt;

&lt;p&gt;Since these trigger phrases will be programmed by the user, it sounds like they won’t be fine-grained enough to accept variable inputs. While it would be awesome to, for example, be able to say “order 2 pizzas” and have it parse each word to understand quantity and product, the reality sounds like it will be closer to “order pizza” and the app will guide you through the details.&lt;/p&gt;

&lt;p&gt;One curiosity I’m anxious to see is how all of this fits into the Shorcuts app. Workflow the app is capable of requesting user input for variables, but what if this went a step further and allowed Siri to not only trigger by the phrase, in this case “order pizza”, but could also ask follow-up questions like “what toppings?”, “what size?” and “how many?”. These will be more difficult of course, and likely won’t be available immediately, but it would really complete the autonomous nature that this concept is creating.&lt;/p&gt;

&lt;p&gt;Earlier this year, Google showed off an AI feature that attempted to mimic a human being calling over the phone for use as their assistant. It was intended to set appointments and things of that nature, but ultimately came off a little too uncanny and creepy for a lot of people. While the idea is neat, it takes much of the human/AI grey area too far. What Apple could accomplish with these new functions is an alternative option to Google’s AI: A way for the user to quickly and effortlessly accomplish the same tasks, but without the creepy phone call to somewhere.&lt;/p&gt;

&lt;p&gt;We’ve already seen Apple’s ability to integrate with ride sharing and restaurant booking via Siri. No phone calls are needed, but the user can quickly request what is needed and get a result. Shortcuts has the potential to take this to the next level and allow third-parties to develop their own options for booking appointments, ordering food, etc. While this will depend on the companies to build support, it would allow a clear separation of that uncanny valley and allow the same work to be done. This also leaves far less room for error, as a properly developed app would be able to know what problems they may run into, rather than an AI that hopefully is able to respond when confronted with an unexpected human question.&lt;/p&gt;

&lt;p&gt;Overall, Siri Shortcuts are still in early days. We haven’t even seen the full Shortcuts app yet, so it’s hard to know just where the separation from Workflow to Shortcuts exists. The fact that we have any integration with iOS is a huge leap forward, let alone the fact that third-party apps will be able to tie into not only the Shortcuts app, but Siri voice triggers and the various suggestions throughout the ecosystem. These will all continue to evolve into something much more complex that everyone can benefit from.&lt;/p&gt;</content>

      
      
      
      
      

      <author>
          <name>Aaron Dippner</name>
        
        
      </author>

      

      
        <category term="apple" />
      
        <category term="wwdc" />
      
        <category term="siri" />
      

      
        <summary type="html">At WWDC this week, Apple announced a huge milestone for Siri: Siri Shortcuts. Back when Apple acquired the company behind Workflow, a powerful automation tool for iOS, there was much speculation on just what would happen. Many feared it would disappear, never to be seen again, but over time we still saw bug fix updates come to the Workflow app. At WWDC they showed off Siri Shortcuts, and an app called Shorcuts that will coincide with this. It is very clear that this Shortcuts app is the result of the Workflow acquisition. The layout is almost identical, but the key difference this time around is that it is much more deeply integrated with iOS.</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">WWDC 2018</title>
      <link href="/wwdc-2018" rel="alternate" type="text/html" title="WWDC 2018" />
      <published>2018-06-05T13:49:00-04:00</published>
      <updated>2018-06-05T13:49:00-04:00</updated>
      <id>/wwdc-2018</id>
      <content type="html" xml:base="/wwdc-2018">&lt;p&gt;Apple’s World Wide Developer Conference (WWDC) for 2018 is underway, and to kick things off they had their announcements on Monday, June 4th. While rumors leading up to this event were pretty sparse, the overall tone was that this would be a bug fix year more than a feature-heavy one. Right off the bat they made it clear there would be no hardware announcements, this was all about software. They dove right in to explaining that they were doing a lot to improve performance and stability (Apple’s way of saying “bug fixes”) and even pointed out that these gains alone would make for a great year (roll credits, show is over), but they didn’t stop there. Over the next two hours they went on to explain a plethora of features that were widely unexpected for this year.&lt;/p&gt;

&lt;p&gt;There was a bit too much to cover here, so I’ll try to tackle a few favorites (though I’m sure I’ll still forget some of those!). For me, the biggest surprise and my favorite announcement was the Siri Shorcuts. This is a combination of a few things, but a lot of it ties into the Shortcuts app that will be coming out for iOS 12. This appears to be the result of Apple’s acquisition of the Workflow app and team, as it strongly resembles it.&lt;/p&gt;

&lt;p&gt;Effectively, Shortcuts allows the user to create their own “scripts” to run various actions, and by being integrated into iOS now, it looks like they’ll provide even more fine-grained ways to work with this than before. By itself this would be a pretty neat feature, but on top of this, users will be able to assign voice triggers for both the shortcuts they create as well as first and third-party apps that have their own functions. This opens a lot of possibilities up for using Siri, as you can create your own memorable trigger phrases to take whatever actions you want.&lt;/p&gt;

&lt;p&gt;Going yet another step further, voice isn’t the only way a user is required to trigger these shortcuts. The machine learning side of Siri will also be able to recognize patterns in usage and suggest shortcuts to the user in a variety of ways, ranging from Spotlight, the lock screen, even the Siri watch face on the Apple Watch. If a user does a particular action every day at the same time, or location, etc, Siri can recommend this shortcut to the user, allowing them to bypass what would otherwise be a lot of manual steps. As this evolves, this has the potential to be a complete game changer in this space.&lt;/p&gt;

&lt;p&gt;Along with shortcuts showing up on the watch, third parties will be able to integrate with the Siri watch face now as well. This was something everyone has wanted since the watch face was announced last year, so it seems obvious, but none the less this is a great addition.&lt;/p&gt;

&lt;p&gt;The watch is also getting both a native podcasts app as well as support for third party background audio, meaning third party podcasts apps as well. I use Overcast for podcasts, but the developer of it, Marco Arment, has long been unsatisfied with the options available to make a proper watch app. it sounds like Apple has listened, as he is already planning some big updates for Overcast which is great.&lt;/p&gt;

&lt;p&gt;Also on the watch is a feature that was supposed to show up in the first generation of the watch and quietly disappeared by launch, walkie-talkie. I’m not sure what the reason for the delay was, but either way, it’s here now and looks like it should be a pretty handy feature. While I can’t see myself using it all of the time, it could be handy when you just need a quick message, be it to someone across the house, or for quick confirmation if you’re out somewhere. We’ll see how my usage of it evolves once it comes out, but I’m excited to see what it’s like either way.&lt;/p&gt;

&lt;p&gt;Something really interesting coming to the watch is the ability to invoke Siri without using “hey Siri”. They claim it will respond simply by you raising your wrist and speaking the command. They seem pretty confident that it won’t trigger accidentally, but we’ll see how that plays out. This has a lot of potential to be useful, but I’m still a bit skeptical just yet.&lt;/p&gt;

&lt;p&gt;A nice update coming to both the watch and iOS are notifications. People have long complained about notifications lacking a way to group them, so finally that request has been heard. Not only can notifications be grouped, but iOS will also allow you to easily tweak notification settings from from each one. You’ll be able to have them silently go straight to notification center instead of pinging you, which is really useful. Siri will also be able to suggest changes to the notifications, presumably based on how much you do or don’t interact with them. Do Not Disturb mode is also being enhanced so you don’t need to disable notifications entirely, but rather can just turn on DND for an hour, or have it turn off when you leave a location.&lt;/p&gt;

&lt;p&gt;Another interesting feature for the watch is Student ID cards. It’s not clear if this will branch out to more sooner than later, but it seems users will not need a full blown ID badge around college campuses. Rather, their watch will be able to work as their ID and the NFC capabilities of the watch will be able to work with readers to authenticate students, pay for snacks, laundry, etc.&lt;/p&gt;

&lt;p&gt;Enough about watchOS though (that could be a post of its own!), iOS is getting some big changes that I love too. Group FaceTime will finally be a thing, supporting up to 32 users! They have a pretty nice UI for it that isn’t as jarring as most that I’ve used seem to be. Users will be able to hop in and out on demand like a chat room, which is pretty useful too.&lt;/p&gt;

&lt;p&gt;Apple also demoed some new ARkit functionality, using LEGOs in a way that brought them to life. I’m a little conflicted on this, as half of the fun for me with LEGOs has always been interacting with them using my imagination, but their presentation does present it more as a way to extend the fun. Either way, they’re making some huge strides in ARkit, especially only being a year old. It’s clear they’re laying down a foundation for something huge further down the road, as in, glasses.&lt;/p&gt;

&lt;p&gt;Outside of that, another one of my favorites include the performance improvements they started off with. When it was announced, I was skeptical that we’d even notice a difference here. After loading the beta up on my iPad Air 2 (now nearly 4 years old and sluggish), it’s not just that it feels like a new device, but the perceived performance enhancements almost seem faster than it was on day one. Not only do I get more life out of this aging device, it’s even better than ever! I’m excited to see how this works across my other devices, as users have reported the same improvements across iPhone and watchOS, which is very promising.&lt;/p&gt;

&lt;p&gt;Overall, while there’s always room for improvement, I think this was a very promising WWDC. It was filled with way more than most of us were expecting, and lays down a foundation for bigger things in the coming years. I’m pretty excited to see how things unfold, but it seems like the betas are incredibly fast and stable already, so that’s a great start. Perhaps we’ll be in for something huge in the fall?&lt;/p&gt;</content>

      
      
      
      
      

      <author>
          <name>Aaron Dippner</name>
        
        
      </author>

      

      
        <category term="apple" />
      
        <category term="wwdc" />
      
        <category term="ios" />
      
        <category term="watchos" />
      
        <category term="siri" />
      

      
        <summary type="html">Apple’s World Wide Developer Conference (WWDC) for 2018 is underway, and to kick things off they had their announcements on Monday, June 4th. While rumors leading up to this event were pretty sparse, the overall tone was that this would be a bug fix year more than a feature-heavy one. Right off the bat they made it clear there would be no hardware announcements, this was all about software. They dove right in to explaining that they were doing a lot to improve performance and stability (Apple’s way of saying “bug fixes”) and even pointed out that these gains alone would make for a great year (roll credits, show is over), but they didn’t stop there. Over the next two hours they went on to explain a plethora of features that were widely unexpected for this year.</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">E.T. Phone Home(Pod)</title>
      <link href="/e-t-phone-home-pod" rel="alternate" type="text/html" title="E.T. Phone Home(Pod)" />
      <published>2018-02-12T14:21:00-05:00</published>
      <updated>2018-02-12T14:21:00-05:00</updated>
      <id>/e-t-phone-home-pod</id>
      <content type="html" xml:base="/e-t-phone-home-pod">&lt;p&gt;When Apple announced the HomePod and it’s price of $349, I was a little put off, hoping for something cheaper that would allow me to plug into my existing speakers. My interest was more on Siri than the speaker/music aspect of it, but I understand their positioning in such a space, they need to be premium. Pre-orders came and went without me, I decided I wanted to hear some reviews from actual people instead of media outlets before deciding. As expected, early reviews as folks unboxed their units were very positive for the sound, but a bit underwhelmed by Siri. The sound has been the big seller for this device, so of course I would hope it would be good, but as more and more folks compared it to fancier speakers, the more interested I became.&lt;/p&gt;

&lt;p&gt;Ultimately, I decided it was worth at least trying one out during Apple’s return window and see where I land. I picked one up from the local mall and plugged it in over my mantel. At first I was pretty unimpressed, the sound seemed good, but not amazing. I did quickly realize we were mostly playing music from the ’60s, like the Beatles, which may not have been recorded to really show this thing off. Next we queued up some modern pop songs with a mix of highs, mids and lows to really demo the range. This is definitely where the HomePod shines. It’s not like older music is bad on it, but I realized there is only so much you’ll be able to differentiate from older recordings.&lt;/p&gt;

&lt;p&gt;Later that day we tried AirPlaying the Apple TV audio to the HomePod to see how well it works as a sound bar of sorts. It works, with somehow less delay than my other AirPlay speakers even (there is typically a 2-second delay between pressing pause/play and the actual result, but they all stay in sync otherwise). It is more quiet than music on the same device, but it still showed me how much we’ve been lacking from the standard TV speakers. This is something that a proper sound system would probably be equally impressive with, but having none of that, it’s nice to have one device solve multiple problems. There’s a lot of potential for this to be the perfect solution for us when two HomePods can be paired together in stereo.&lt;/p&gt;

&lt;p&gt;Finally I had a chance to sit down with it on the evening of the second day and properly compare it to my existing stereo system that I would say is probably the “best” in the house. It’s a custom system I pieced together, consisting of a standalone amp attached to some decent bookshelf speakers and an AirPort Express providing AirPlay input to the amp. While my tests weren’t super thought out, I tried to place the speakers and HomePod in ways that wouldn’t get in each other’s ways but still provide a good test for their typical usage. They say the HomePod needs to play music for a little while to calibrate itself after it’s been moved, so perhaps that explains things, but at first I was a little disappointed. While HomePod was better, it didn’t seem like by much. It certainly fills a room better, anywhere you walk the sound is pretty consistent, but sitting in front of both, the sound seemed only marginally better. I decided to put on an Apple Music playlist, hoping it would have some songs just for this purpose. It wasn’t until the song “Fitzpleasure” by alt-J came on that the difference became incredibly clear. The range on the song really set things apart and made my old system sound hollow and tinny. I hate to use the comparison, but it really was similar to going from a standard display to retina. Hearing the difference, it’s hard to go back to the other&lt;sup&gt;&lt;a href=&quot;#one&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;

&lt;p&gt;One observation I’ve made about this speaker is how it automatically tunes itself for each song. This is something in the past I would have had to do pretty regularly either on my amp directly or via a software equalizer, and is something I really don’t care to interact with. I realize that’s the least audiophile thing to say, but I’m no audiophile 🙂 I think I pretty well sum up the market this device is for, average consumers who just want music to sound good without any extra effort. I don’t want to mess with speaker placement, tucking wires or messing with equalizers. I just want a device I can plug in and have results that work as expected without any tweaking. HomePod definitely does great at that, and not just because it learns your room, but in general because it has a lot of engineering in the DSP to really make a lot happen from a small device.&lt;/p&gt;

&lt;p&gt;When it comes to music, HomePod is a winner. It has reminded me of why I ever invested in a decent sound system to start with, not to mention my collection of vinyls. It wasn’t about sound quality as much as just the experience of sitting and actively listening to music instead of passively while doing something else. HomePod makes me want to sit and enjoy music with friends in a way I haven’t in a long time.&lt;/p&gt;

&lt;p&gt;HomePod is marketed at having “room filling sound”. The concept seems pretty simple, it just needs to make the room have sound from anywhere. This is actually a pretty tough trick typically, since most stereo systems use two speakers pointed forward. You’ll hear music outside of there, but it tends to very quickly lose its quality as you veer from being directly in front. HomePod has a circular array of tweeters, and using their fancy software and processor, they can adjust the sound based on the room dynamics. This means, typically, anywhere I went in the room after it adjusted itself (which happens during the first song you play) the sound was the same. It’s one of those things you kind of have to experience to really feel it, but it transforms the way you listen to music in a lot of ways.&lt;/p&gt;

&lt;p&gt;Beyond all of that, there is of course the Siri functionality. I will definitely say that personally, I’ve been using Siri since my iPhone 4S which I got a few weeks after launch. It has been something I find incredible value in, and the evolution of features over time has only increased that value for me. I know plenty of people like to trash talk it, say it doesn’t work, or that it is “light years behind &amp;lt;Alexa/Google Assistant&amp;gt;”. While this debate is best saved for another time, overall my experience on the iPhone with Siri has been pretty much on par with Google Assistant and in most cases&lt;sup&gt;&lt;a href=&quot;#two&quot;&gt;2&lt;/a&gt;&lt;/sup&gt; far surpasses Alexa. Notice I said on iPhone though.&lt;/p&gt;

&lt;p&gt;HomePod Siri unfortunately comes out of the gate crippled a bit more than its iOS version. While 95% of my queries have been fine, there have been a few times where it simply says “I can’t do that on HomePod” or similar, even for something simple like weight conversions. It tended to work after I adjusted the wording slightly, but that’s still unfortunate. They market this device as being a musicologist, and thusly, Siri is ideal for music requests. This has been overall a great success, but I have had it hiccup on requests like “Who’s the drummer in this?” for bands where the answer is obvious, such as the Beatles. It was a more obscure song, but it should still be able to get that data regardless of what is attached to each song. However, this really was only a problem for that song, overall it’s been able to tell me all sorts of random facts about the music, from who plays what, to who wrote the specific song in bands like the Beatles where it regularly alternates.&lt;/p&gt;

&lt;p&gt;Another quirky aspect of HomePod with regards to Siri is Apple’s approach to tying in things like messages and reminders. HomePod allows you to set reminders or send messages with Siri, but only if you give permission to, because unfortunately they don’t do any type of voice detection to ensure the wrong user isn’t attempting to read/send messages. This also means these services are only tied to one user for now, but I imagine all of this will change with an update in the near future. Ideally they will provide multiple voice detection (Google already can, and Siri can on iOS) that can tie to each user’s profiles.&lt;/p&gt;

&lt;p&gt;An interesting approach they took was forcing these interactions to occur on the user’s phone. Basically, it detects the request and passes it to the phone for processing. This also aids in a kind of security, as these interactions can only occur when the user is on the same wifi. At least this way no one will be reading your messages if you’re not home. I don’t now if they plan to keep this design, but I do kind of like it from an engineering aspect. By separating this out, in theory it only needs to store data about who’s phone to send to, so potentially as they add support for more users, it could simply know how to route to the user’s phone and do the rest. This keeps things secure and private in some ways, but it’s not like there’s much one could extract from HomePod either way. I also could see this being a way they allow users to authorize interactions, using Touch/Face ID when needed, since it all interacts with the phone anyway.&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;one&quot;&gt;&lt;/a&gt;
One of the most impressive parts of the Siri experience on HomePod is how well it can hear you, regardless of how loud music may be. I’ve done multiple tests with volume at 100% and am still able to make requests to Siri at what I would consider a normal speaking volume. You certainly won’t be whispering at 100% volume, but I think you can still talk slightly quieter than if you were talking to someone else in the same room at that volume. At 60% you can easily talk lower than regular speaking volume and Siri will hear you perfectly. I haven’t had any mistakes in what it heard me request so far either, which is a common issue people complain about on iOS. Clearly this thing benefits a ton from having always-on power and an array of mics. The internal processing it does with all of the sound definitely helps it pick up these sounds over the other noise, which is super useful for play/pause commands.
&lt;a name=&quot;two&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;(1)&lt;/strong&gt; As a follow up, I did end up doing some further tuning and concluded that my existing setup is a lot better than I thought initially. The HomePod still does better at the “room filling” aspect, as mine requires sitting in the “sweet spot”&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;(2)&lt;/strong&gt; Alexa does have tons of “skills”, but I’ve never known anyone who uses these are more than a party trick, and most of them are clunky even for that. There are going to be a few things each assistant does better than the other, with Alexa’s multiple timers being better than Siri’s single timer, but I’ve learned tricks like using alarms and reminders to solve that ages ago.&lt;/p&gt;</content>

      
      
      
      
      

      <author>
          <name>Aaron Dippner</name>
        
        
      </author>

      

      
        <category term="apple" />
      
        <category term="homepod" />
      
        <category term="siri" />
      
        <category term="airplay" />
      
        <category term="smart-speaker" />
      

      
        <summary type="html">When Apple announced the HomePod and it’s price of $349, I was a little put off, hoping for something cheaper that would allow me to plug into my existing speakers. My interest was more on Siri than the speaker/music aspect of it, but I understand their positioning in such a space, they need to be premium. Pre-orders came and went without me, I decided I wanted to hear some reviews from actual people instead of media outlets before deciding. As expected, early reviews as folks unboxed their units were very positive for the sound, but a bit underwhelmed by Siri. The sound has been the big seller for this device, so of course I would hope it would be good, but as more and more folks compared it to fancier speakers, the more interested I became.</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">Siri Speaker</title>
      <link href="/siri-speaker" rel="alternate" type="text/html" title="Siri Speaker" />
      <published>2017-05-01T14:17:00-04:00</published>
      <updated>2017-05-01T14:17:00-04:00</updated>
      <id>/siri-speaker</id>
      <content type="html" xml:base="/siri-speaker">&lt;p&gt;Rumors are ramping up lately that Apple will make a Siri speaker soon. This seems reasonable as that space is growing fast and they don’t want to be left behind. Some concerns I’ve read were things like needing a screen for some tasks where these assistants can fall short. What if Apple’s magic up its sleeve is using their Handoff/Continuity features to pass over to your phone when a screen is needed? You make a request, but perhaps it’s a really long article that comes back. Rather than have her read the entire thing, an icon shows up on your phone/iPad/watch or she even vibrates it (based on knowing who asked) so you can read it.&lt;/p&gt;

&lt;p&gt;Another useful feature could be integration with AirPods and the likes. They can’t do “Hey Siri”, but if you’re wearing them and ask it, they could be used to playback the response instead of the speaker. This device, which would always be plugged in, could have some new chip like the W1 for Bluetooth, allowing multiple users to have AirPods paired to it and act as a central hub when you’re home, no need to have a phone handy. These are definitely some lofty goals, but worth discussing at the very least.&lt;/p&gt;

&lt;p&gt;Different thought: What if we’re on the completely wrong track with this? What if instead, Apple uses the W1 Bluetooth tech and builds a Bluetooth speaker and mic that has some slight “smarts” to it, in that, it can sense multiple users’ voices for “Hey Siri” but ultimately it still routes back to the user’s connected phone? You could have these placed all over the house for fairly cheap, and being always on/plugged in, they could have far better Bluetooth range and capabilities. This wouldn’t limit the device to only being able to read out voice replies, as the user’s phone would do the actual work and they could just look at their phone at any point to see the same response. This also would make the possibility of adding more functions like mesh wifi, and still keep the price point lower.&lt;/p&gt;

&lt;p&gt;Routing to the user’s phone would be great for privacy too. The centralized device, accessible from anyone in the home, could just be “dumb”, the real “smarts” happening on the individual’s private, encrypted device. This could be tricky, since it would need really good voice detection and possibly a way to authenticate, but would certainly follow Apple’s “Think Different” motto.&lt;/p&gt;</content>

      
      
      
      
      

      <author>
          <name>Aaron Dippner</name>
        
        
      </author>

      

      
        <category term="apple" />
      
        <category term="smart-speaker" />
      
        <category term="w1" />
      
        <category term="bluetooth" />
      
        <category term="iphone" />
      

      
        <summary type="html">Rumors are ramping up lately that Apple will make a Siri speaker soon. This seems reasonable as that space is growing fast and they don’t want to be left behind. Some concerns I’ve read were things like needing a screen for some tasks where these assistants can fall short. What if Apple’s magic up its sleeve is using their Handoff/Continuity features to pass over to your phone when a screen is needed? You make a request, but perhaps it’s a really long article that comes back. Rather than have her read the entire thing, an icon shows up on your phone/iPad/watch or she even vibrates it (based on knowing who asked) so you can read it.</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">Theories on Apple’s W1 pairing</title>
      <link href="/theories-on-apples-w1-pairing" rel="alternate" type="text/html" title="Theories on Apple's W1 pairing" />
      <published>2016-12-15T18:44:33-05:00</published>
      <updated>2016-12-15T18:44:33-05:00</updated>
      <id>/theories-on-apples-w1-pairing</id>
      <content type="html" xml:base="/theories-on-apples-w1-pairing">&lt;p&gt;Since my last post, I’ve been putting a lot more thought into the pairing capabilities of Apple’s new W1 chip. A lot of folks are convinced the W1 itself is where the magic happens. I’m not saying that is impossible, but since Apple insists you must have the latest iOS/macOS and iCloud enabled for the seamless pairing to work, it should be obvious there is a lot more software involved than hardware.&lt;/p&gt;

&lt;p&gt;If the W1 isn’t responsible for this pairing magic, what is? Without having a pair of W1 headphones I can only speculate, but after a lot of Bluetooth research I have some theories. For starters, if the hardware were responsible, yet allows non-Apple hardware to be paired, it seems unusual to go out of the way to build special functionality into an otherwise full Bluetooth stack. In theory, if the hardware could pair with more than 1-2 devices (something Bluetooth can already do), what would stop a non-Apple device from being the 3rd or 4th device to pair?&lt;/p&gt;

&lt;p&gt;Some theories have been floating around that the W1 uses the new Bluetooth 5 specification. While this isn’t impossible or even that unlikely (except for it just being adopted a week ago), it only explains the better battery and reception of these devices. The specification doesn’t go into details about pairing, so regardless of Bluetooth 5, that doesn’t seem to be the culprit here.&lt;/p&gt;

&lt;p&gt;It should be noted that Bluetooth has supported up to 8 device pairing for a while, but most hardware simply doesn’t support that. We could simply be seeing a pair of headphones that supports 8 “slots” for remembering devices, but that hasn’t been explicitly called out by Apple, nor should that require the latest iOS/macOS either. While this may be partly responsible, you would expect at least a little more delay or work to get other devices paired. From everything we’ve seen, the moment one device is paired, they all can see it.&lt;/p&gt;

&lt;p&gt;My current running theory is that we’re seeing something similar or related to the Handoff functionality Apple has supported for a few generations now. I believe the real “magic” happens on the OS during pairing. The tricky part is that during pairing, unique information is passed around to encrypt and ensure the two devices are talking to each other. I believe this data is what is requiring iCloud, and somehow they are either “spoofing” with a fake identifier or injecting data on each device, then using Handoff as the means to identify which device has the “Bluetooth baton” so to speak. As we already know, you have to select which device uses the headphones manually, and this process does seem to have a slight delay. This could be Handoff making sure the old device “disconnects” and the new one “connects” in a way that the headphones seamlessly believe is effectively the same device.&lt;/p&gt;

&lt;p&gt;This is all just theory, I haven’t touched an actual W1 set of headphones yet to put any of this to the test, but most of my theory revolves around the need for the latest OS and iCloud to do this pairing. If this were using any form of standard Bluetooth, there’s really no reason the OS should matter, as it doesn’t on other headphones that can be paired with multiple devices.&lt;/p&gt;

&lt;p&gt;Why would Apple make such a big deal out of the W1 then? Marketing mostly. People don’t (usually) buy Apple products to understand the tech, but rather the exact opposite. They want something that “just works” and by branding anything with the W1 as offering this “seamless pairing” you ensure a good user experience. I’m not faulting them for making it seem like the W1 is doing all of the heavy lifting, I’m mostly just curious if my theories are correct :)&lt;/p&gt;</content>

      
      
      
      
      

      <author>
          <name>Aaron Dippner</name>
        
        
      </author>

      

      
        <category term="apple" />
      
        <category term="w1" />
      
        <category term="airpods" />
      
        <category term="bluetooth" />
      

      
        <summary type="html">Since my last post, I’ve been putting a lot more thought into the pairing capabilities of Apple’s new W1 chip. A lot of folks are convinced the W1 itself is where the magic happens. I’m not saying that is impossible, but since Apple insists you must have the latest iOS/macOS and iCloud enabled for the seamless pairing to work, it should be obvious there is a lot more software involved than hardware.</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">Apple’s W1 Wireless Chip (and why it may not be so “magical”)</title>
      <link href="/apples-w1-wireless-chip-and-why-it-may-not-be-so-magical" rel="alternate" type="text/html" title="Apple's W1 Wireless Chip (and why it may not be so &quot;magical&quot;)" />
      <published>2016-12-13T03:08:42-05:00</published>
      <updated>2016-12-13T03:08:42-05:00</updated>
      <id>/apples-w1-wireless-chip-and-why-it-may-not-be-so-magical</id>
      <content type="html" xml:base="/apples-w1-wireless-chip-and-why-it-may-not-be-so-magical">&lt;p&gt;Earlier this year, Apple announced they were dropping the headphone jack from the iPhone 7 to push for a truly wireless future. To further encourage this, they also announced a handful of new wireless headphones between their Beats branding as well as their own Apple branding. Both Beats and Apple (AirPods) headphones would utilize the new, Apple exclusive W1 wireless chip.&lt;/p&gt;

&lt;p&gt;Much of the hype around the W1 was simultaneously avoiding the word “Bluetooth” while trying to sound like a magical fix to all of our woes with current Bluetooth headphones. Since the announcement, very little official information about the W1 has come to light. They did release the Beats Solo3 and Powerbeats 3 headphones which included the W1, giving folks a chance to test out the various claims.&lt;/p&gt;

&lt;p&gt;Let’s do a quick review of some of the biggest benefits of the W1:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Fast pairing with devices&lt;/strong&gt; (they make a point that iCloud and iOS 10 are required for this, but effectively you just go to the device you want to use headphones on and as long as they are turned on, you should see them in the list where AirPlay devices normally show up)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Great battery life&lt;/strong&gt; (while not specified, this seems likely due to their custom chip being made at a smaller manufacturing process than most)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Better reception/signal&lt;/strong&gt; (e.g. less hiccups and skipping when your phone is in your pocket)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Apple has also stated (while carefully tiptoeing around ever using the name “Bluetooth”) they are using a Class 1 chip, which in itself addresses the reception/signal side of things. To be able to use a Class 1 (typically seen in devices with more dedicated power) specification implies the chip sips energy a LOT better than other devices, and thus the W1 is likely built on a smaller process.&lt;/p&gt;

&lt;p&gt;While I’m not denying the W1 is custom, I have a feeling it does less of the “magic” I see so many blogs and forums speculating on. More than anything, I believe the W1 provides a better &lt;strong&gt;quality&lt;/strong&gt; Bluetooth chip than most, allowing better signal and battery life, but that is likely it. We already have seen in reviews that these devices function as normal Bluetooth devices on non-Apple hardware, and can even work as far back as the iPhone 5, but to get the “magic” features, iOS 10 is definitely required.&lt;/p&gt;

&lt;p&gt;None of this is to say that Apple isn’t working &lt;em&gt;some&lt;/em&gt; kind of magic in how this all works, but I doubt much of it is in the W1 specifically. Where the W1 likely &lt;em&gt;does&lt;/em&gt; help, is the fact that they designed and built it in house. This means they can define what happens with this device during the pairing and broadcasting within the Bluetooth specifications. They can also ensure things like the name and MAC address fit within a criteria they can look for on the OS. MAC address may play less of a factor, but I still have some theories on how important it could be which I will touch on later.&lt;/p&gt;

&lt;p&gt;Some quick background on Bluetooth might help here. When pairing a device, there are all sorts of boring things that happen, but among them it provides some specifications such as what type of device this is, what it is capable of, identifiers like MAC addresses, a name for display in the OS and things like that. I suspect this is where the real magic happens. Bluetooth has already been able to pair instantly to known hosts, or via NFC “tap to pair” functionality, but what about the initial pairing? What sets the W1 apart when used on an Apple device?&lt;/p&gt;

&lt;p&gt;Let’s take what we know about AirPods as a place to start. We know that when you get a brand new set, you can simply open the lid of the case and with your iPhone nearby, iOS will pop up a “card” that shows what you’re trying to pair and an easy button to do so. I’ve seen some folks who are very impressed with this process, and while I agree this takes out &lt;em&gt;so much&lt;/em&gt; of the headache of traditional Bluetooth pairing in iOS, this isn’t proof that the W1 was required. Instead, this can be explained simply by the fact that when Bluetooth is broadcasting the initial pairing info, the OS knows what to look for. Part of the info being broadcast is a UUID for each service the device can provide, so you just keep an eye out for one specific UUID in the OS, knowing full well this relates to the W1, and give it special priority over any other Bluetooth doing the same thing. No W1 magic here, just a well-informed OS and better UI/UX than before.&lt;/p&gt;

&lt;p&gt;We can agree pairing may not be anything too unusual, in fact in some ways this is just catching up to the NFC pairing Android has already been capable of for some time. What about the ability for these headphones to instantly be paired with every other device you own? This still doesn’t &lt;em&gt;require&lt;/em&gt; the W1, but some custom work wouldn’t have hurt if they really wanted to. I have been toying with a few ideas on how to best accomplish this task, and this is where I mentioned MAC addresses could be handy.&lt;/p&gt;

&lt;p&gt;One potential option for iCloud pairing would be that you “spoof” the MAC address being paired. You could use an entirely made up one, or by simply storing the first paired device’s ID in the cloud. There’s a little more to it than just that, but storing IDs, keys and the likes is the broad overview here. On your other devices, if they want to pair, they can simply spoof their own ID with the one that is stored and any other necessary encryption/pairing info, combined with some of Apple’s handoff/continuity “magic”, telling each device they are allowed to take their turn with the headphones. This isn’t necessarily the best way to do this, but seems like an easy work around, especially when you control the ecosystem like Apple does. This could work fairly reliably, since you only have to guarantee it works with devices running the proper version of the OS as well as using iCloud (which it states is required).&lt;/p&gt;

&lt;p&gt;Ultimately, most folks won’t care &lt;em&gt;how&lt;/em&gt; Apple achieved any of this, just that the hassle of Bluetooth pairing and device switching is easier. The reason this is a bit concerning, however, is because this opens a lot of potential for Apple to never fix the issue beyond their own Beats and Apple-branded hardware. Sure, they &lt;em&gt;could&lt;/em&gt; license the W1 chip to third-parties who can make their own headphones and speakers, but I don’t know how all of that might fit into the picture given they don’t seem to have the rights to call this “Bluetooth”, or at least are shying away from the name. It would be very Apple-like to require certification if they intend to share this at all, so don’t count on seeing support for your favorite brand anytime soon.&lt;/p&gt;

&lt;p&gt;Perhaps the most annoying part of all of this is the fact that some obvious remedies to this problem have existed for a long time. Since iOS introduced the Control Center (swipe up from the bottom of the screen), there has been a Bluetooth (and WiFi) icon which lets you enable/disable it quickly. On Android, if you long-press this icon it jumps to the settings page for Bluetooth, where you can quickly select a device. As if that weren’t an easy enough fix, Apple later introduced the 3D Touch feature for the iPhone 6s and 7, which would make perfect sense for this use case. Ideally it wouldn’t even take you to the settings page (as that can be arguably poor UX) but instead pop up a bubble or card with a list of devices. Of course, by doing it that way (and in turn allowing any devices to quickly pair) there would be no reason to focus on this “magical” W1 chip and the devices it powers.&lt;/p&gt;

&lt;p&gt;Don’t get me wrong, I’m just as excited as most for the prospect of easy pairing and an end to some of the most annoying aspects of Bluetooth. This whole thought process was more of a way to figure out how they are doing it, in hopes other OSes can benefit and mimic this functionality for everyone else’s benefit. Bluetooth has plenty of inherent flaws, but when it comes to the pairing process, I have a feeling the host software is mostly to blame for not making things easier. Again, some have tried, as we see with Android’s quick settings and NFC pairing. The moment Apple added NFC (for ApplePay) to the iPhone 6, I had high hopes we might see NFC pairing, but I suspect they would argue there are security concerns with that method.&lt;/p&gt;

&lt;p&gt;By ensuring only their W1 chip (and maybe certified variants of it) gives pairing priority, Apple can provide the “best” user experience and just happen to make money on it at the same time. Could the Bluetooth specification be updated to make things more consistent? Sure, I’d love to see both sides cooperate in a way to identify accessories better and ensure faster pairing across the board. Will we see this anytime soon? Since the Bluetooth 5 spec was recently put in place, I wouldn’t hold my breath.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;tl;dr:&lt;/strong&gt; most functionality being claimed possible (or at least strongly implied) because of the W1 could fairly easily be done in software on the host OS. Some of this functionality has already existed (NFC pairing on Android is similar) and by opening up this “magic” could make for a better UX for everyone with so many other Bluetooth devices, but instead we will likely have to pay a premium for faster/easier pairing in the Apple ecosystem for the foreseeable future.&lt;/p&gt;</content>

      
      
      
      
      

      <author>
          <name>Aaron Dippner</name>
        
        
      </author>

      

      
        <category term="apple" />
      
        <category term="airpods" />
      
        <category term="w1" />
      
        <category term="wireless" />
      
        <category term="bluetooth" />
      
        <category term="iphone" />
      
        <category term="beats" />
      
        <category term="class-1" />
      
        <category term="nfc" />
      

      
        <summary type="html">Earlier this year, Apple announced they were dropping the headphone jack from the iPhone 7 to push for a truly wireless future. To further encourage this, they also announced a handful of new wireless headphones between their Beats branding as well as their own Apple branding. Both Beats and Apple (AirPods) headphones would utilize the new, Apple exclusive W1 wireless chip.</summary>
      

      
      
    </entry>
  
</feed>
