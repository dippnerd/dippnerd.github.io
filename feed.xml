<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.7.4">Jekyll</generator><link href="/feed.xml" rel="self" type="application/atom+xml" /><link href="/" rel="alternate" type="text/html" /><updated>2020-03-16T21:47:36-04:00</updated><id>/</id><title type="html">dippnerd</title><subtitle>things to nerd out about</subtitle><entry><title type="html">Catalyst - the future of Mac apps?</title><link href="/mac-catalyst" rel="alternate" type="text/html" title="Catalyst - the future of Mac apps?" /><published>2020-02-05T20:27:06-05:00</published><updated>2020-02-05T20:27:06-05:00</updated><id>/mac-catalyst</id><content type="html" xml:base="/mac-catalyst">&lt;p&gt;Back in June 2019 at WWDC Apple announced Mac Catalyst, a new way to build apps that share one common codebase that can run across iPadOS, iOS and macOS. Very shortly after this announcement, they also announced the new SwiftUI, an easy way to create apps for Mac, iPad, iPhone, etc. Immediately people were joking about how Apple announced and promptly killed Catalyst in the same presentation, but I don’t think this is quite the case.&lt;/p&gt;

&lt;p&gt;First, a little deeper dive into Catalyst. What this was pitched as is a way to write an iOS/iPadOS app, and with little to no effort (it’s literally as simple as checking a box!) you can magically add support for macOS. We saw some demo apps of this in iOS 12 the year before (Stocks, Voice Recorder, Home) that were less than ideal, but technically got the job done. Where these apps didn’t exist before on macOS, suddenly they did.&lt;/p&gt;

&lt;p&gt;Unfortunately there’s a lot of small details that weren’t quite so painless. Most apps won’t be as simple as just checking a box, you’ll likely need to separate out some code that differentiates between platforms for both UI appeal, but also functionality (or lack there of in some cases) that differs. Those problems aside, it is still an impressive feat to consider how much &lt;em&gt;less&lt;/em&gt; effort it takes to build an app with Catalyst compared to building two completely separate apps.&lt;/p&gt;

&lt;p&gt;Heading back to SwiftUI, the thing that gets easily overlooked in this debate of SwiftUI vs Catalyst is that SwiftUI is still only one piece of the puzzle. It’s also a piece that is compatible with Catalyst, whose roots go far deeper than just the UI. SwiftUI is a great way to “declare” your UI, but it doesn’t do much else, it’s not meant to. Catalyst, however, is responsible for not only UI, but also a lot of other underlying frameworks and APIs that aren’t necessarily exposed to macOS apps the same way.&lt;/p&gt;

&lt;p&gt;When writing an app for iOS, then learning macOS, it is quick to see they both share some things, and act wildly different with others. If you want, you can write separate iOS and macOS apps using SwiftUI and the respective frameworks for each platform, but ultimately you’ll be still doing twice the work. When using SwiftUI &lt;em&gt;with&lt;/em&gt; Catalyst, you can share a common codebase. It’s easy to miss the difference, but it is there.&lt;/p&gt;

&lt;p&gt;Traditionally, macOS apps have been built using a framework called AppKit, while iOS apps use UIKit. They are very uniquely separate frameworks for different tasks, but this is why SwiftUI alone does not mean you get two apps from one codebase. Catalyst, in a sense, is a sort of “translator” of your code, to allow it to run on macOS. Behind the scenes, while I’m not entirely sure what Apple does to make this work, I suspect it’s an effort that is not being replaced immediately with SwiftUI.&lt;/p&gt;

&lt;p&gt;I believe Catalyst is more of a long-term strategy at Apple to not only share apps across platforms, but to also bring the platforms themselves closer together. There are still so many thing macOS is lacking that iOS/iPadOS have (or at least can do better). The same could be said on the reverse. The tricky part is figuring out where to draw lines in the sand for any of this. Catalyst feels like Apple saying “we prefer the iOS way of building apps, so if you want iOS functionality, this is the way”.&lt;/p&gt;

&lt;p&gt;While we don’t have 100% feature parity with Catalyst yet, it is still young. I think what we’ll see down the road is the expansion of features like Siri Shortcuts or the Shortcuts app, but only available to Catalyst apps. If you build an app with SwiftUI but via AppKit as a standalone app, you’ll not only have to maintain a separate codebase from your iOS app, but you’ll also miss out on features that Catalyst provides from iOS. This makes sense in a lot of ways, as it means users who want AppKit can still use it, but over time it will stop getting new features and eventually even get dropped altogether (probably not for a while though).&lt;/p&gt;

&lt;p&gt;Speaking of Siri Shortcuts, this would be the easy way to avoid having to add support for Shortcuts to legacy apps. Only Catalyst apps get these features, AppKit gets left behind. Sure, developers can still make AppKit apps, and will make great ones I’m sure, but to get that “iOS on Mac” experience, it’ll have to be Catalyst.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;tl;dr&lt;/strong&gt;: Catalyst is way more than just UI, while SwiftUI is basically just UI (hence the name). To get a true cross-platform, one-codebase end result, Catalyst is a way safer bet than SwiftUI+AppKit/UIKit. Expect features to be exclusive to Catalyst instead of AppKit over time.&lt;/p&gt;</content><author><name>Aaron Dippner</name></author><category term="apple" /><category term="mac" /><category term="catalyst" /><category term="swift" /><category term="swiftui" /><summary type="html">Back in June 2019 at WWDC Apple announced Mac Catalyst, a new way to build apps that share one common codebase that can run across iPadOS, iOS and macOS. Very shortly after this announcement, they also announced the new SwiftUI, an easy way to create apps for Mac, iPad, iPhone, etc. Immediately people were joking about how Apple announced and promptly killed Catalyst in the same presentation, but I don’t think this is quite the case.</summary></entry><entry><title type="html">iPod, HomePod, iPad, HomePad?</title><link href="/homepad" rel="alternate" type="text/html" title="iPod, HomePod, iPad, HomePad?" /><published>2019-08-20T13:12:20-04:00</published><updated>2019-08-20T13:12:20-04:00</updated><id>/homepad</id><content type="html" xml:base="/homepad">&lt;p&gt;There has been a growing market for voice assistant devices in the past few years. These range from small, $30 circular devices that can plug into other speakers, to fully-integrated speakers, evolving into ones that include screens even.&lt;/p&gt;

&lt;p&gt;Some recent examples include Amazon’s Echo Show, a device that includes both the Alexa assistant as well as screen to display song lyrics, recipes, etc. Google’s take on this is the Google Home Hub, similar build with a focus on voice commands that give visual results.&lt;/p&gt;

&lt;p&gt;Apple’s only foray into this space of stand-alone, dedicated voice assistant hardware has been the HomePod. It’s often touted as the “Siri Speaker” even though Apple insists it’s more of a music speaker that happens to have Siri for an interface. It comes with plenty of useful features outside of music though, ranging from multiple timers to being able to get calendar info, weather and other things Siri does on the phone already.&lt;/p&gt;

&lt;p&gt;Apple is notoriously silent about future products, but people often speculate whether they will try to compete with the likes of Echo Show or Google Home Hub by making a similar assistant-focused device with a screen. The common argument against this is that we already have such a device, the iPad. It has Siri, can do many of the same features as HomePod already, and serves as a multi-purpose device instead of being stuck in one room with very narrow features.&lt;/p&gt;

&lt;p&gt;While I agree that the iPad does fill many of these gaps already, there are many reasons a “HomePad” device could be appealing (for the right price of course). For starters, Siri just doesn’t work the same on the iPad as the voice assistants on these other screen-focused devices. Siri can present some basic info hands-free, but often requires the user to authenticate to do more. This is good for things like reading messages and private content like notes, but for just bringing up a basic recipe or showing song lyrics, unlocking shouldn’t be needed. The interfaces for those functions also tend to require a few taps to get where you’re going as well, so Siri would need a revamped UI to better compete in this space.&lt;/p&gt;

&lt;p&gt;With a dedicated “HomePad”, it could remove the “i” focus of the iPad, being individual-based instead of multi-user. Instead, this device could focus on things that don’t necessary need security authentication, but allow restrictions for the user in terms of what content can be accessed. Similar to how HomePod has “personal requests” which allows the user to access calendar events and such, this feature could exist on “HomePad” as well, and have the ability to disable it just the same.&lt;/p&gt;

&lt;p&gt;The main goal would be to have an assistant in places where your hands are often dirty or otherwise inaccessible, particularly the kitchen. Being able to play videos, music (with lyrics), show recipes and other basic web site results would make this a lot more useful than Siri on the iPad currently is. On the flip side, instead of making dedicated hardware, opening the iPad to do all of these things could be an easy gateway into homes that have iPads everywhere already. Sure, they aren’t buying new hardware, but they also aren’t buying the competitor’s assistant just to get the same job done.&lt;/p&gt;</content><author><name>Aaron Dippner</name></author><category term="apple" /><category term="homepod" /><category term="homepad" /><category term="ipad" /><category term="siri" /><category term="google" /><category term="amazon" /><summary type="html">There has been a growing market for voice assistant devices in the past few years. These range from small, $30 circular devices that can plug into other speakers, to fully-integrated speakers, evolving into ones that include screens even.</summary></entry><entry><title type="html">SwiftUI - Using Timer for UI refreshes</title><link href="/swiftui-timer-ui-refresh" rel="alternate" type="text/html" title="SwiftUI - Using Timer for UI refreshes" /><published>2019-07-25T14:16:26-04:00</published><updated>2019-07-25T14:16:26-04:00</updated><id>/swiftui-timer-ui-refresh</id><content type="html" xml:base="/swiftui-timer-ui-refresh">&lt;p&gt;At WWDC this year, one of Apple’s biggest announcements wasn’t a particular feature of the new OSes, but rather a new way to write UIs for your apps using Swift. This new framework, named SwiftUI, uses a declaritive syntax to easily define your UI in far fewer lines of code than before. Along with SwiftUI, Apple announced another framework, Combine, which helps with handling asynchronous events. This post won’t dive into the fundamentals of either of these, there are plenty of others out there already. Instead, this post is intended to work through some challenges I ran into when trying to upgrade my app, &lt;a href=&quot;https://itunes.apple.com/us/app/just-timers/id1453573845?ls=1&amp;amp;mt=8&quot;&gt;Just Timers&lt;/a&gt;, to use SwiftUI.&lt;/p&gt;

&lt;p&gt;When I wrote Just Timers, I used UIKit by pushing my content into a UITableView, pretty standard. A nice feature of UITableView for an app that needs the UI to constantly refresh is the ability to simply use a timer to repeat at a given interval and run a method that refreshes your table, like so:&lt;/p&gt;

&lt;div class=&quot;language-swift highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kt&quot;&gt;Timer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;scheduledTimer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;timeInterval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;selector&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;#selector(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;TimerViewController.refreshCells&lt;/span&gt;&lt;span class=&quot;kd&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;userInfo&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;nil&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;repeats&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The &lt;code class=&quot;highlighter-rouge&quot;&gt;refreshCells&lt;/code&gt; method iterates over the visible cells of the table and changes various parts of the UI depending on what values the object in that cell is in. If a value changed from paused to running, the button gets updated to reflect this; if the timer expired, the UI changes color, etc. Calling the method on a reoccuring timer is easy, but updating your UI in here can get rather complex very fast.&lt;/p&gt;

&lt;p&gt;Meanwhile, in SwiftUI, you can very easily describe your UI by breaking it into multiple views, each responsible for their own piece of the picture. You track each state inside of the given view, then when the view is updated, whatever state each piece is in gets reflected in the UI. This vastly simplifies both your UI code and keeping track of states, but it posed a new problem I wasn’t quite prepared for:  Something like &lt;code class=&quot;highlighter-rouge&quot;&gt;refreshCells&lt;/code&gt; doesn’t work the same way here. We don’t reference individual cells like UITableView, everything is just defined in the UI and changes when the state of that view changes.&lt;/p&gt;

&lt;p&gt;Enter Combine. In order to utilize Timer in a way that will allow my views to “subscribe” to it firing, we need to create a wrapper class that will house our timer. Using Combine, we make this wrapper a BindableObject and add the necessary requirements. Effectively, this class will contain our timer instance, then every time the timer fires, it will call the willChange method to let subscribers know it just fired off an event.&lt;/p&gt;
&lt;div class=&quot;language-swift highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;SwiftUI&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Combine&lt;/span&gt;

&lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;TimerWrapper&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;ObservableObject&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;objectWillChange&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;ObservableObjectPublisher&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;timer&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Timer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;
    &lt;span class=&quot;kd&quot;&gt;func&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;withTimeInterval&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;interval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Double&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;timer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;?&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;invalidate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;timer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Timer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;scheduledTimer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;withTimeInterval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;interval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;repeats&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;objectWillChange&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;send&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    
    &lt;span class=&quot;kd&quot;&gt;func&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;stop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;timer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;?&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;invalidate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We’ll need a way to reference this timer in SwiftUI, so next we go to our SceneDelegate and update scene(…willConnectTo) to create our timer instance and pass it into the root view controller as an environment object:&lt;/p&gt;
&lt;div class=&quot;language-swift highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;windowScene&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scene&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as?&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;UIWindowScene&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;window&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;UIWindow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;windowScene&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;windowScene&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;window&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rootViewController&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;UIHostingController&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;rootView&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;contentView&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;environmentObject&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;timerObject&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;environmentObject&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;timerWrapper&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;window&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;window&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;window&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;makeKeyAndVisible&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Keep in mind we created our instance of TimerWrapper and have to start it (providing an interval in seconds). This instance will remain active in SceneDelegate, and by utilizing &lt;code class=&quot;highlighter-rouge&quot;&gt;.environmentObject&lt;/code&gt; we can make this instance accessible anywhere in our code now.&lt;/p&gt;

&lt;p&gt;Now, anywhere we want our UI to update with this given interval, just add this to your view:&lt;/p&gt;
&lt;div class=&quot;language-swift highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;@EnvironmentObject&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;timerWrapper&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;TimerWrapper&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;You don’t need to do anything else with that value. By simply referencing it in your view, the publisher will automatically nofify each view that is subscribed, causing them to redraw their view due to the state change.&lt;/p&gt;

&lt;p&gt;Something to consider:  It’s easy to think &lt;em&gt;“I’ll just put this on my root view and everything will update!”&lt;/em&gt; Technically this is true, but in my experience it causes buttons and other interactions to become difficult to use. Instead, consider the views that will need updated specifically. In my case, the string that displays my timer’s current value is the only thing that needs updated by this timer. By putting that into its own view, you not only simplify code by separating it, but you can also reference the timer wrapper in this view only to prevent the entire UI getting bogged down.&lt;/p&gt;

&lt;p&gt;I hope this helps anyone out trying to something similar. I didn’t come to all of this on my own, credit goes to &lt;a href=&quot;https://stackoverflow.com/a/56905649/9012764&quot;&gt;this Stack Overflow answer&lt;/a&gt; and &lt;a href=&quot;https://www.reddit.com/r/iOSProgramming/comments/cf219v/force_swiftui_list_contents_to_update/eu6rk28/&quot;&gt;this response&lt;/a&gt; to my problem on Reddit.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;Update 21 February 2020:&lt;/em&gt;&lt;/strong&gt; &lt;em&gt;SwiftUI and Combine had some growing pains through the beta periods and have changed along the way. The code snippets above have been updated with current changes, like ‘willChange’ becoming ‘objectWillChange’.&lt;/em&gt;&lt;/p&gt;</content><author><name>Aaron Dippner</name></author><category term="apple" /><category term="swiftui" /><category term="timers" /><summary type="html">At WWDC this year, one of Apple’s biggest announcements wasn’t a particular feature of the new OSes, but rather a new way to write UIs for your apps using Swift. This new framework, named SwiftUI, uses a declaritive syntax to easily define your UI in far fewer lines of code than before. Along with SwiftUI, Apple announced another framework, Combine, which helps with handling asynchronous events. This post won’t dive into the fundamentals of either of these, there are plenty of others out there already. Instead, this post is intended to work through some challenges I ran into when trying to upgrade my app, Just Timers, to use SwiftUI.</summary></entry><entry><title type="html">AirPods 2: Electric Boogaloo</title><link href="/airpods-2-electric-boogaloo" rel="alternate" type="text/html" title="AirPods 2&amp;#58; Electric Boogaloo" /><published>2019-03-28T07:07:36-04:00</published><updated>2019-03-28T07:07:36-04:00</updated><id>/airpods-2-electric-boogaloo</id><content type="html" xml:base="/airpods-2-electric-boogaloo">&lt;p&gt;Last week Apple started surprising everyone with a product refresh every day. Starting on Monday, Apple refreshed the iPad Air and Mini, Tuesday saw a refresh of the iMac lineup and finally Wednesday saw the refresh of AirPods. While every product was a bit surprising to see, for most people the AirPods refresh was the most unexpected. There had been rumors of a refresh coming, but they were always pretty vague on details and timing. After much waiting, finally Apple revealed AirPods 2: Electric Boogaloo.&lt;/p&gt;

&lt;p&gt;While some expected a complete redesign (or at least a dark color option), AirPods 2 are actually a fairly minor upgrade over the first generation. The biggest change is the added support for “Hey Siri” via the AirPods. Previously, you had to rely on double-tapping one AirPod (assuming you assigned Siri to that specific AirPod too) to summon the assistant. Now, AirPods 2 lets you simply utter “Hey Siri” into the air and the assistant will chime in. You can still assign a double-tap gesture to each AirPod, but no need for Siri for that anymore, giving room for more control.&lt;/p&gt;

&lt;p&gt;While “Hey Siri” is the biggest change, that doesn’t mean the other changes are any less welcomed. The first generation used a chip Apple called the W1, their first wireless chip, to provide some of the cutting-edge features the first generation boasted. AirPods 2 now contain what Apple calls the H1 headphone chip, though in reality it is likely more of a marketing rebranding than a completely new chip. The H1 boasts up to 2x faster switching between active devices, 1.5x faster connection time for phone calls, up to 30 percent lower gaming latency, longer talk time, and of course the “Hey Siri” functionality.&lt;/p&gt;

&lt;p&gt;One of my biggest complaints about the first generation AirPods was that, while it was nice to only have to pair them to one device and have them show up across the rest of my devices, often you would hit massive waiting periods while they switch from one device to another. Sometimes it was quick, but other times it would take longer than if I had just re-paired them manually, which could get frustrating. Some of this is simply the nature of Bluetooth, combined with the fact that some devices may be using an older Bluetooth chip or software. AirPods 2 do indeed fulfill some of their improved switching claims, but I’ve noticed this primarily relates to newer devices using Bluetooth 5.0, such as the iPhone XS and Apple Watch Series 4. When switching between the iPhone XS and my 2018 iPad (Bluetooth 4.2) the delays are mostly the same as the previous generation.&lt;/p&gt;

&lt;p&gt;Regarding the 1.5x faster connection time for phone calls, I can’t speak to this specifically for phone calls yet, but I have noticed that the connected sound seems to happen much sooner than on previous generations. In the past, you would pop them out of their case and into your ears and sometimes it would be quick, other times it might take a few seconds before you hear the tone. For the most part with AirPods 2, by the time I have the first one in my ear I already hear the sound before I get a chance to put the second in. If this is any indicator of what to expect when taking a phone call, I think it will be a huge improvement.&lt;/p&gt;

&lt;p&gt;Since I don’t play a lot of games, I can’t give real good feedback on the lower latency, but it does seem lower in general when interacting with user interfaces that provide sound feedback. The first generation weren’t terrible at this, but it was generally just noticeable enough to be annoying, so this hopefully fixes that.&lt;/p&gt;

&lt;p&gt;One of the requirements for the new AirPods was updating to the latest OS versions. I’m not positive just what changed with that, but since watchOS 5.2 was delayed a few days I did wait until then to give a proper test between the iPhone XS and Apple Watch Series 4. As mentioned above, it does seem like when switching AirPods between two Bluetooth 5.0 devices have nearly instant switching, which is a great improvement.&lt;/p&gt;

&lt;p&gt;AirPods have always been able to pair with both the phone and watch simultaneously, but generally it was shaky as to just which device would pick up tap gestures or Siri commands, which was always frustrating. It seems like the new “Hey Siri” on AirPods 2 prioritizes the phone, so that’s much appreciated (as the watch can’t do all of the same tasks as the phone). We’ll see over the longterm if this still holds up, but so far so good.&lt;/p&gt;

&lt;p&gt;Outside of the AirPods themselves, the case also got a minor update that adds support for Qi wireless charging. I didn’t opt for this case since I have no problems charging mine every day, but it does seem useful for folks looking to just set their AirPods down somewhere to let them charge.&lt;/p&gt;

&lt;p&gt;So far my only real “complaint” would be on the “Hey Siri” side of things. When you use the trigger phrase directly on the phone, you get a chime to let you know it heard you. With the AirPods there is no longer the same chime, Siri simply responds to your command, but this isn’t always immediate if she needs to fetch data from the web or something. This delay can cause you to think Siri didn’t hear you and cause you to try again, but I’ve been able to train myself to be more patient.&lt;/p&gt;

&lt;p&gt;Another interesting detail is that the phone appears to wake the screen whenever you invoke Siri, regardless of whether you cover up the mics so only AirPods would be hearing you. This seems unnecessary if the phone is on your pocket, but they may have ways to detect that too. It’s a minor detail, but one that I found a bit unexpected given the context that Siri should only display something if there is an expectation of visual feedback over audio-only.&lt;/p&gt;

&lt;p&gt;Overall I’m very pleased with this update of the AirPods. For the most part they’ve fixed all of my complaints with the last generation. The delays that still exist seem to be more at the fault of older devices, so that will likely improve as everything moves to Bluetooth 5.0+ anyway. “Hey Siri” is a hugely welcomed feature for me, as it has been the missing piece to the whole Siri ecosystem in my opinion.&lt;/p&gt;</content><author><name>Aaron Dippner</name></author><category term="apple" /><category term="airpods" /><category term="siri" /><summary type="html">Last week Apple started surprising everyone with a product refresh every day. Starting on Monday, Apple refreshed the iPad Air and Mini, Tuesday saw a refresh of the iMac lineup and finally Wednesday saw the refresh of AirPods. While every product was a bit surprising to see, for most people the AirPods refresh was the most unexpected. There had been rumors of a refresh coming, but they were always pretty vague on details and timing. After much waiting, finally Apple revealed AirPods 2: Electric Boogaloo.</summary></entry><entry><title type="html">Just Timers App Launched</title><link href="/just-timers-app" rel="alternate" type="text/html" title="Just Timers App Launched" /><published>2019-03-22T18:31:01-04:00</published><updated>2019-03-22T18:31:01-04:00</updated><id>/just-timers-app</id><content type="html" xml:base="/just-timers-app">&lt;p&gt;Today I’ve launched my first iOS app, &lt;a href=&quot;https://itunes.apple.com/us/app/just-timers/id1453573845?ls=1&amp;amp;mt=8&quot;&gt;Just Timers&lt;/a&gt;. Since iOS can natively only handle a single timer at a time, I’ve frequently found myself frustrated when I need more than one. While the App Store does contain some apps that can create multiple timers, they’re all missing one crucial feature:  Siri control.&lt;/p&gt;

&lt;p&gt;That’s where Just Timers comes in, with the ability to use the iOS 12 feature “Siri Shortcuts” to assign your own voice phrases to timer actions like pause, resume and restart. While this is intended as the primary method of interacting with your timers, I’ve also extended the abilities into the iOS app &lt;a href=&quot;https://itunes.apple.com/us/app/shortcuts/id915249334?mt=8&quot;&gt;Shortcuts&lt;/a&gt;, which provides automation features for iOS. There is an extensive write up available on the &lt;a href=&quot;https://justtimers.app/help/shortcuts/&quot;&gt;Just Timers website&lt;/a&gt; which goes into detail on what commands are supported by the API, but long story short you can do everything Siri Shortcuts can and more. With a downloadable Shortcut available on that page, you can even create new timers completely hands free!&lt;/p&gt;

&lt;p&gt;Please check out &lt;a href=&quot;https://itunes.apple.com/us/app/just-timers/id1453573845?ls=1&amp;amp;mt=8&quot;&gt;Just Timers&lt;/a&gt; and give me some feedback if you can!&lt;/p&gt;</content><author><name>Aaron Dippner</name></author><summary type="html">Today I’ve launched my first iOS app, Just Timers. Since iOS can natively only handle a single timer at a time, I’ve frequently found myself frustrated when I need more than one. While the App Store does contain some apps that can create multiple timers, they’re all missing one crucial feature: Siri control.</summary></entry><entry><title type="html">Belkin Thunderbolt 2 Express HD Dock Review</title><link href="/belkin-thunderbolt-2-express-hd-dock" rel="alternate" type="text/html" title="Belkin Thunderbolt 2 Express HD Dock Review" /><published>2018-08-31T18:49:03-04:00</published><updated>2018-08-31T18:49:03-04:00</updated><id>/belkin-thunderbolt-2-express-hd-dock</id><content type="html" xml:base="/belkin-thunderbolt-2-express-hd-dock">&lt;p&gt;This is very late to the game, but since there has been a slight resurgence in demand for 2015 Macbook Pro’s of late, I figured it might not hurt to give a short review on this unit. The Belkin Thunderbolt 2 Express HD Dock attempts to be a lot crammed into a relatively small package. At the time of me writing this, it’s been out for a few years and is priced pretty much on par with the other options like it. The nice thing about buying it now, however, is you can pick them up used for a good bit cheaper.&lt;/p&gt;

&lt;p&gt;The main appeal of this device is it can connect 8 different devices over one Thunderbolt 2 cable, with the option to further daisy-chain additional Thunderbolt devices. It comes with three USB 3 ports, two Thunderbolt 2 ports, HDMI, Ethernet and two audio out ports (one includes mic support). For me, the main appeal was a way to consolidate the mess of wires I had plugged into my laptop for my particular needs. Prior to this dock, I had: an Ethernet adapter plugged in over Thunderbolt, a wired keyboard and trackpad (the trackpad wasn’t required to stay plugged in, it’s just a preference of mine), wired external speakers, HDMI out and of course power. Thanks to this dock, I am now down to just a single Thunderbolt 2 cable and a power cable. I’d certainly prefer this to be one wire, but it’s vastly superior to how I was doing it.&lt;/p&gt;

&lt;p&gt;The primary reason I wanted to move to this solution was because I was finding myself rarely using my laptop outside of my desk, solely because it was such a hassle to remove all of these cables. Sure, I could have a wireless keyboard and trackpad, wireless speakers, and even ditch the Ethernet, but my gigabit network speeds are many times faster than my wifi, I already own the wired keyboard that I like, and I don’t like wireless speakers (they’re usually Bluetooth and lossy/flaky at best). Keeping things how I prefer, I never have to deal with charging my trackpad or pairing to the speakers, instead, this dock allows me the comfort of all of these preferences through one cable.&lt;/p&gt;

&lt;p&gt;Enough of the why, the real question is how well does this thing work? First off, it should be noted that I did buy this used on Amazon, so there is always a chance that any problems I have with it may be due to that. I was leery when reading reviews on all of the docks of this sort available, as they often had similar complaints regarding issues with HDMI or Ethernet in particular. A few claimed their Ethernet speeds were 100mbit/s instead of the advertised gigabit, which was concerning, as it would make my whole reason for this device a bit less necessary if my wifi speeds are better than that.&lt;/p&gt;

&lt;p&gt;I’ve only had this dock a few days, but overall, so far so good. I tested Ethernet speeds between the official Apple dongle and this dock, and they are generally comparable, a few times the dock even outperforms the dongle. So far, no issues with HDMI either. In the past I’ve had occasions were HDMI directly from the HDMI port on my laptop gave me trouble, but nothing of the sort &lt;em&gt;yet&lt;/em&gt;. My keyboard and trackpad are plugged in and working fine (though I previously had my trackpad plugged into one of the USB ports of my keyboard, once using the dock this resulted in a message about power every time I connected to the dock so I just moved the trackpad to charge directly from the dock, no more message). The only real complaints I have so far are with the speaker connection (and this is largely my own fault for having a particularly quirky setup).&lt;/p&gt;

&lt;p&gt;I have a set of desktop speakers connected to a desktop computer, then a cable that runs from the line in on that computer to the dock (previously to my laptop). Since moving to the dock, I have noticed a slight feedback hum over my speakers, but immediately rearranged some wires and found the power cable was causing the majority of the noise. Moving it away helped, but hasn’t completely fixed it. There may be some other fix, but for now I’ve minimized it enough to not care. The only other complaint, and this really doesn’t affect me directly, is how hot the dock gets while in use. I realize I’m nearly maxing out it’s ports, but it gets surprisingly warm driving my 4K monitor (which is advertises it can do). I don’t know that this is the culprit, but it makes the most sense given how low-bandwidth the rest of the connections are. While my Ethernet can do gigabit, the dock still gets warm while idle and driving my display. If the display goes to sleep, however, the dock does cool down, so that seems to be the common factor. Again, this really doesn’t impact me overall, as it still works and I rarely need to touch it (nor is it too hot to touch, just warmer than I’d like). This could cause some longterm problems, but I guess time will tell.&lt;/p&gt;

&lt;p&gt;I should add, one of the main reasons I picked this dock over a few other options I was considering was largely because it has the USB port and audio jack (with mic) on the front, as well as the ones on the back. This is minor for most people, but since I have the desktop speakers plugged in on the back, I wanted something I could still easily plug in headphones and other USB peripherals into as needed. If these aren’t needful things for you, the other docks may suffice (but I can’t vouch for them). For me, this seems like a winner.&lt;/p&gt;</content><author><name>Aaron Dippner</name></author><summary type="html">This is very late to the game, but since there has been a slight resurgence in demand for 2015 Macbook Pro’s of late, I figured it might not hurt to give a short review on this unit. The Belkin Thunderbolt 2 Express HD Dock attempts to be a lot crammed into a relatively small package. At the time of me writing this, it’s been out for a few years and is priced pretty much on par with the other options like it. The nice thing about buying it now, however, is you can pick them up used for a good bit cheaper.</summary></entry><entry><title type="html">Siri Shortcuts</title><link href="/siri-shortcuts" rel="alternate" type="text/html" title="Siri Shortcuts" /><published>2018-06-08T17:10:24-04:00</published><updated>2018-06-08T17:10:24-04:00</updated><id>/siri-shortcuts</id><content type="html" xml:base="/siri-shortcuts">&lt;p&gt;At WWDC this week, Apple announced a huge milestone for Siri: Siri Shortcuts. Back when Apple acquired the company behind Workflow, a powerful automation tool for iOS, there was much speculation on just what would happen. Many feared it would disappear, never to be seen again, but over time we still saw bug fix updates come to the Workflow app. At WWDC they showed off Siri Shortcuts, and an app called Shorcuts that will coincide with this. It is very clear that this Shortcuts app is the result of the Workflow acquisition. The layout is almost identical, but the key difference this time around is that it is much more deeply integrated with iOS.&lt;/p&gt;

&lt;p&gt;The Shortcuts app itself would be pretty handy in general, you’ll be able to build Automator-style “Shortcuts” that can trigger actions throughout the OS. Apple showed that third-parties will also be able to integrate with this, so the benefits begin to snowball into something very interesting. Apple didn’t stop there, however. Combine all of this with the “Siri” side of things:  Shortcuts will be able to trigger using custom voice phrases that the user can assign for Siri. Telling Siri “laundry time” could kick off a custom Shortcut that the user created, for example. The icing on the cake with all of this is that, beyond just voice, Siri will recognize patterns in usage for these Shortcuts and offer recommendations for them throughout the OS.&lt;/p&gt;

&lt;p&gt;Some examples of Siri recommendations include Spotlight/Siri search, where the user can pull down on the home screen and it will present some suggested shortcuts based on relevant context (time, location, etc). Running late for a meeting? It may offer to text your boss. Going to the gym? It may recognize a gym Shortcut you setup to start a workout and listen to a podcast.&lt;/p&gt;

&lt;p&gt;These recommendations can also be helped along by third-party apps. These apps can “donate” Siri relevant data for it to analyze and find patterns with. Apple offers various ways to “nudge” Siri in the right direction if you know you want the user to see this information within certain times, events, etc, but overall it sounds like it should be pretty capable of learning and offering useful suggestions.&lt;/p&gt;

&lt;p&gt;Some other ways these Shortcuts will come up include the lock screen and the Siri watch face for Apple watch. This is particularly exciting, as it will be possible for many tasks to be carried off in the background, the user simply needs to invoke it from the watch face or trigger phrase.&lt;/p&gt;

&lt;p&gt;While some of these details are still unclear, these Siri Shortcuts offer a huge leap in capabilities for Siri. What used to be a fairly limited set of SiriKit domains will not be opened pretty wide for third-parties to do as they please. It hasn’t been made clear if apps will be able to request additional information, such as asking the user for input without opening the app, but if this isn’t available at launch, surely it won’t be far behind.&lt;/p&gt;

&lt;p&gt;Since these trigger phrases will be programmed by the user, it sounds like they won’t be fine-grained enough to accept variable inputs. While it would be awesome to, for example, be able to say “order 2 pizzas” and have it parse each word to understand quantity and product, the reality sounds like it will be closer to “order pizza” and the app will guide you through the details.&lt;/p&gt;

&lt;p&gt;One curiosity I’m anxious to see is how all of this fits into the Shorcuts app. Workflow the app is capable of requesting user input for variables, but what if this went a step further and allowed Siri to not only trigger by the phrase, in this case “order pizza”, but could also ask follow-up questions like “what toppings?”, “what size?” and “how many?”. These will be more difficult of course, and likely won’t be available immediately, but it would really complete the autonomous nature that this concept is creating.&lt;/p&gt;

&lt;p&gt;Earlier this year, Google showed off an AI feature that attempted to mimic a human being calling over the phone for use as their assistant. It was intended to set appointments and things of that nature, but ultimately came off a little too uncanny and creepy for a lot of people. While the idea is neat, it takes much of the human/AI grey area too far. What Apple could accomplish with these new functions is an alternative option to Google’s AI: A way for the user to quickly and effortlessly accomplish the same tasks, but without the creepy phone call to somewhere.&lt;/p&gt;

&lt;p&gt;We’ve already seen Apple’s ability to integrate with ride sharing and restaurant booking via Siri. No phone calls are needed, but the user can quickly request what is needed and get a result. Shortcuts has the potential to take this to the next level and allow third-parties to develop their own options for booking appointments, ordering food, etc. While this will depend on the companies to build support, it would allow a clear separation of that uncanny valley and allow the same work to be done. This also leaves far less room for error, as a properly developed app would be able to know what problems they may run into, rather than an AI that hopefully is able to respond when confronted with an unexpected human question.&lt;/p&gt;

&lt;p&gt;Overall, Siri Shortcuts are still in early days. We haven’t even seen the full Shortcuts app yet, so it’s hard to know just where the separation from Workflow to Shortcuts exists. The fact that we have any integration with iOS is a huge leap forward, let alone the fact that third-party apps will be able to tie into not only the Shortcuts app, but Siri voice triggers and the various suggestions throughout the ecosystem. These will all continue to evolve into something much more complex that everyone can benefit from.&lt;/p&gt;</content><author><name>Aaron Dippner</name></author><category term="apple" /><category term="wwdc" /><category term="siri" /><summary type="html">At WWDC this week, Apple announced a huge milestone for Siri: Siri Shortcuts. Back when Apple acquired the company behind Workflow, a powerful automation tool for iOS, there was much speculation on just what would happen. Many feared it would disappear, never to be seen again, but over time we still saw bug fix updates come to the Workflow app. At WWDC they showed off Siri Shortcuts, and an app called Shorcuts that will coincide with this. It is very clear that this Shortcuts app is the result of the Workflow acquisition. The layout is almost identical, but the key difference this time around is that it is much more deeply integrated with iOS.</summary></entry><entry><title type="html">WWDC 2018</title><link href="/wwdc-2018" rel="alternate" type="text/html" title="WWDC 2018" /><published>2018-06-05T13:49:00-04:00</published><updated>2018-06-05T13:49:00-04:00</updated><id>/wwdc-2018</id><content type="html" xml:base="/wwdc-2018">&lt;p&gt;Apple’s World Wide Developer Conference (WWDC) for 2018 is underway, and to kick things off they had their announcements on Monday, June 4th. While rumors leading up to this event were pretty sparse, the overall tone was that this would be a bug fix year more than a feature-heavy one. Right off the bat they made it clear there would be no hardware announcements, this was all about software. They dove right in to explaining that they were doing a lot to improve performance and stability (Apple’s way of saying “bug fixes”) and even pointed out that these gains alone would make for a great year (roll credits, show is over), but they didn’t stop there. Over the next two hours they went on to explain a plethora of features that were widely unexpected for this year.&lt;/p&gt;

&lt;p&gt;There was a bit too much to cover here, so I’ll try to tackle a few favorites (though I’m sure I’ll still forget some of those!). For me, the biggest surprise and my favorite announcement was the Siri Shorcuts. This is a combination of a few things, but a lot of it ties into the Shortcuts app that will be coming out for iOS 12. This appears to be the result of Apple’s acquisition of the Workflow app and team, as it strongly resembles it.&lt;/p&gt;

&lt;p&gt;Effectively, Shortcuts allows the user to create their own “scripts” to run various actions, and by being integrated into iOS now, it looks like they’ll provide even more fine-grained ways to work with this than before. By itself this would be a pretty neat feature, but on top of this, users will be able to assign voice triggers for both the shortcuts they create as well as first and third-party apps that have their own functions. This opens a lot of possibilities up for using Siri, as you can create your own memorable trigger phrases to take whatever actions you want.&lt;/p&gt;

&lt;p&gt;Going yet another step further, voice isn’t the only way a user is required to trigger these shortcuts. The machine learning side of Siri will also be able to recognize patterns in usage and suggest shortcuts to the user in a variety of ways, ranging from Spotlight, the lock screen, even the Siri watch face on the Apple Watch. If a user does a particular action every day at the same time, or location, etc, Siri can recommend this shortcut to the user, allowing them to bypass what would otherwise be a lot of manual steps. As this evolves, this has the potential to be a complete game changer in this space.&lt;/p&gt;

&lt;p&gt;Along with shortcuts showing up on the watch, third parties will be able to integrate with the Siri watch face now as well. This was something everyone has wanted since the watch face was announced last year, so it seems obvious, but none the less this is a great addition.&lt;/p&gt;

&lt;p&gt;The watch is also getting both a native podcasts app as well as support for third party background audio, meaning third party podcasts apps as well. I use Overcast for podcasts, but the developer of it, Marco Arment, has long been unsatisfied with the options available to make a proper watch app. it sounds like Apple has listened, as he is already planning some big updates for Overcast which is great.&lt;/p&gt;

&lt;p&gt;Also on the watch is a feature that was supposed to show up in the first generation of the watch and quietly disappeared by launch, walkie-talkie. I’m not sure what the reason for the delay was, but either way, it’s here now and looks like it should be a pretty handy feature. While I can’t see myself using it all of the time, it could be handy when you just need a quick message, be it to someone across the house, or for quick confirmation if you’re out somewhere. We’ll see how my usage of it evolves once it comes out, but I’m excited to see what it’s like either way.&lt;/p&gt;

&lt;p&gt;Something really interesting coming to the watch is the ability to invoke Siri without using “hey Siri”. They claim it will respond simply by you raising your wrist and speaking the command. They seem pretty confident that it won’t trigger accidentally, but we’ll see how that plays out. This has a lot of potential to be useful, but I’m still a bit skeptical just yet.&lt;/p&gt;

&lt;p&gt;A nice update coming to both the watch and iOS are notifications. People have long complained about notifications lacking a way to group them, so finally that request has been heard. Not only can notifications be grouped, but iOS will also allow you to easily tweak notification settings from from each one. You’ll be able to have them silently go straight to notification center instead of pinging you, which is really useful. Siri will also be able to suggest changes to the notifications, presumably based on how much you do or don’t interact with them. Do Not Disturb mode is also being enhanced so you don’t need to disable notifications entirely, but rather can just turn on DND for an hour, or have it turn off when you leave a location.&lt;/p&gt;

&lt;p&gt;Another interesting feature for the watch is Student ID cards. It’s not clear if this will branch out to more sooner than later, but it seems users will not need a full blown ID badge around college campuses. Rather, their watch will be able to work as their ID and the NFC capabilities of the watch will be able to work with readers to authenticate students, pay for snacks, laundry, etc.&lt;/p&gt;

&lt;p&gt;Enough about watchOS though (that could be a post of its own!), iOS is getting some big changes that I love too. Group FaceTime will finally be a thing, supporting up to 32 users! They have a pretty nice UI for it that isn’t as jarring as most that I’ve used seem to be. Users will be able to hop in and out on demand like a chat room, which is pretty useful too.&lt;/p&gt;

&lt;p&gt;Apple also demoed some new ARkit functionality, using LEGOs in a way that brought them to life. I’m a little conflicted on this, as half of the fun for me with LEGOs has always been interacting with them using my imagination, but their presentation does present it more as a way to extend the fun. Either way, they’re making some huge strides in ARkit, especially only being a year old. It’s clear they’re laying down a foundation for something huge further down the road, as in, glasses.&lt;/p&gt;

&lt;p&gt;Outside of that, another one of my favorites include the performance improvements they started off with. When it was announced, I was skeptical that we’d even notice a difference here. After loading the beta up on my iPad Air 2 (now nearly 4 years old and sluggish), it’s not just that it feels like a new device, but the perceived performance enhancements almost seem faster than it was on day one. Not only do I get more life out of this aging device, it’s even better than ever! I’m excited to see how this works across my other devices, as users have reported the same improvements across iPhone and watchOS, which is very promising.&lt;/p&gt;

&lt;p&gt;Overall, while there’s always room for improvement, I think this was a very promising WWDC. It was filled with way more than most of us were expecting, and lays down a foundation for bigger things in the coming years. I’m pretty excited to see how things unfold, but it seems like the betas are incredibly fast and stable already, so that’s a great start. Perhaps we’ll be in for something huge in the fall?&lt;/p&gt;</content><author><name>Aaron Dippner</name></author><category term="apple" /><category term="wwdc" /><category term="ios" /><category term="watchos" /><category term="siri" /><summary type="html">Apple’s World Wide Developer Conference (WWDC) for 2018 is underway, and to kick things off they had their announcements on Monday, June 4th. While rumors leading up to this event were pretty sparse, the overall tone was that this would be a bug fix year more than a feature-heavy one. Right off the bat they made it clear there would be no hardware announcements, this was all about software. They dove right in to explaining that they were doing a lot to improve performance and stability (Apple’s way of saying “bug fixes”) and even pointed out that these gains alone would make for a great year (roll credits, show is over), but they didn’t stop there. Over the next two hours they went on to explain a plethora of features that were widely unexpected for this year.</summary></entry><entry><title type="html">AirPort Express as AirPlay Speakers</title><link href="/airplay-speakers" rel="alternate" type="text/html" title="AirPort Express as AirPlay Speakers" /><published>2018-04-19T19:51:42-04:00</published><updated>2018-04-19T19:51:42-04:00</updated><id>/airplay-speakers</id><content type="html" xml:base="/airplay-speakers">&lt;p&gt;A few weeks back it was discovered in an iOS beta that &lt;a href=&quot;https://9to5mac.com/2018/04/04/airplay-2-airport-express/&quot;&gt;AirPort Express devices were showing up as speakers&lt;/a&gt; in the Home app, implying Apple might be updating these devices to support AirPlay 2. This disappeared in the latest beta, but it has since sparked some interest in using AirPort Expresses for AirPlay speakers, so I thought I’d take some time to write about how I use these devices.&lt;/p&gt;

&lt;p&gt;Apple has offered some method of audio streaming to AirPort Expresses for years now, updating the AirPlay protocol along the way. The concept is great, you have a puck that both acts as a wireless router (or extender) &lt;em&gt;and&lt;/em&gt; can stream music over a 3.5mm audio jack. Because it uses this universal standard, you can plug any of your own speakers into it and “magically” have wireless audio anywhere in your house.&lt;/p&gt;

&lt;p&gt;Don’t need the wireless router part? No problem! You can disable wireless altogether if you want to just play music using an ethernet cable, or you can even just let the device work in client mode, where it connects to your wireless router like any other device. Either configuration works great from my experience, I’ve played with a mixture of both.&lt;/p&gt;

&lt;p&gt;I have multiple AirPort Expresses throughout my house used solely for wireless audio, which works out great as I have a bunch of existing amps and speakers to attach them to. One big reason people (myself included) hope to see these devices get updated to AirPlay 2 is because AirPlay 1.x has some very specific limitations. The most noticeable is how there is always a 2-second delay between play/pause for audio while it buffers. When AirPlay first came out, it was so revolutionary that it was easy to overlook this delay, but in recent years competition in this space has grown, making this delay quite annoying. Another limitation is that you can only play music from an iOS device to one AirPlay source at a time. Note I said iOS device, the exceptions here are that iTunes on macOS can play to multiple simultaneously (and even seems to handle the delay issue a bit better) as well as third party apps like &lt;a href=&quot;https://www.rogueamoeba.com/airfoil/&quot;&gt;Airfoil by Rogue Amoeba&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;To give my house the effect of whole-home audio from any device, I’ve had to get a bit creative. While I could just always play music from iTunes on my Mac using the Remote app, it’s outdated and fairly clunky these days. Instead, I want to be able to use any app on any device to stream to every AirPlay speaker at the same time. Thankfully, Rogue Amoeba also makes an app called &lt;a href=&quot;https://www.rogueamoeba.com/airfoil/#satellite&quot;&gt;Airfoil Satellite&lt;/a&gt; for macOS which allows you to stream to your Mac as though it were an AirPlay source. Configuring Airfoil to take the system audio as the source, now I can AirPlay from any device that supports AirPlay and it will transmit that audio to the AirPlay speakers.&lt;/p&gt;

&lt;p&gt;Using Airfoil I can solve at least one issue with AirPlay 1, playing to multiple sources, but in the default state this is even a bit clunky. Unless you leave the speakers connected to Airfoil all the time (I often want to just play directly to one speaker), you have to open the Airfoil app and select which speakers to play to. This is where software like Homebridge comes in handy. I have a write-up over on my &lt;a href=&quot;https://github.com/dippnerd/airfoil-speakers-applescript&quot;&gt;GitHub project&lt;/a&gt; explaining all of the settings I used, but essentially I have scripts tied to a fake lightbulb so HomeKit lets me toggle on/off as well as volume (using the brightness slider). This gives me way more control and flexibility without having to go into an app to turn on the speakers.&lt;/p&gt;

&lt;p&gt;At the bottom of the page I also mention another project I’ve been working on, a &lt;a href=&quot;https://github.com/dippnerd/applescript-flash-briefing&quot;&gt;Flash Briefing&lt;/a&gt; of sorts. There is a fairly deep explanation on that page, but suffice it to say I use this same AirPlay speaker and Airfoil combination to broadcast a flash briefing throughout the entire house each morning. This includes things like weather, calendar events, birthdays, news, etc.&lt;/p&gt;

&lt;p&gt;With the right effort, I suspect you could fully extend this functionality to really do a lot over the speakers, including using it as a quasi-doorbell (but the 2-second delay may be a problem) or other automation triggers like telling you when the mail has arrived, or announcing when dinner is ready. If I ever get around to hard-wiring all of my speakers to talk to one central amp, one could just pipe audio directly out of the Mac instead of over AirPlay, saving that just for times when you wish to stream from a device like your phone, but one thing at a time :)&lt;/p&gt;</content><author><name>Aaron Dippner</name></author><summary type="html">A few weeks back it was discovered in an iOS beta that AirPort Express devices were showing up as speakers in the Home app, implying Apple might be updating these devices to support AirPlay 2. This disappeared in the latest beta, but it has since sparked some interest in using AirPort Expresses for AirPlay speakers, so I thought I’d take some time to write about how I use these devices.</summary></entry><entry><title type="html">Why HomePod isn’t ready for my home</title><link href="/why-i-returned-my-homepod" rel="alternate" type="text/html" title="Why HomePod isn't ready for my home" /><published>2018-02-20T17:42:00-05:00</published><updated>2018-02-20T17:42:00-05:00</updated><id>/why-i-returned-my-homepod</id><content type="html" xml:base="/why-i-returned-my-homepod">&lt;p&gt;I purchased the HomePod nearly two weeks ago, and today it went back to Apple. I still stand by a lot of what I said in my &lt;a href=&quot;/2018/02/12/e-t-phone-home-pod/&quot;&gt;previous article&lt;/a&gt;. As a speaker, HomePod is fantastic device not just for sound, but for ease of use too. It’s going to be hard to find something that has such omni-directional, quality sound. The size of the HomePod is particularly impressive for what all it accomplishes. Best of all, the complete ease of use (especially compared to the traditional amp and speaker setup that may scare some users away) makes it as painless as possible.&lt;/p&gt;

&lt;p&gt;All of that said, while HomePod is a great speaker, it just isn’t ready for my home yet. While Apple by no means lied about what functionality would come with it out of the box, some of the promised features like AirPlay 2 and Stereo Pairing (both announced at WWDC in June) are still missing. On top of that, there was a lot of mystery around what Siri would or wouldn’t do at launch. It wasn’t until I started reading reviews and eventually tried it out myself that I got to see how broken it is compared to Siri on virtually every other device.&lt;/p&gt;

&lt;p&gt;Understand, I’m not by any means trying to say Siri is bad. I love it across most of my devices, and have &lt;a href=&quot;/2017/10/07/in-defense-of-voice-assistants/&quot;&gt;outlined its many uses&lt;/a&gt; to me in the past. The Siri on HomePod, however, is crippled. No matter how you want to look at it, Siri on HomePod is lacking in a lot of ways that other Apple devices already can handle. A big issue for me was voice detection.&lt;/p&gt;

&lt;p&gt;Siri on my iOS devices is trained to my voice, meaning if someone else in my house utters “Hey Siri,” my phone won’t pick up the request. HomePod has the same A8 chip as an iPhone 6, which is capable of the always-on “Hey Siri” (if the phone is plugged in). HomePod should be able to at least offer voice training, but to go a step further, it shouldn’t be too hard to still allow untrained voices to access music, but not my reminders and messages.&lt;/p&gt;

&lt;p&gt;While HomePod is a great speaker, for me personally, I already have some speakers I’m happy with. Sure, they don’t have the omni-directional, room-filling capabilities of the HomePod, but on the grand scale, that’s not something I need just yet (especially not for the money, considering I already have speakers). All I’m really looking for is a device not unlike the Amazon Echo Dot, but with Siri, to plug into my existing speakers. Apple may not be making such a device anytime soon (if ever), but that would be my ideal scenario.&lt;/p&gt;

&lt;p&gt;On the flip side, I certainly won’t say I’ll never buy a HomePod. As I said before, it is perfect for a specific market of people who don’t want to hassle with getting great sound. I still fit that market, but HomePod is going to need to do a bit more to win me back. I need AirPlay 2 and Stereo Pairing to get here, along with improvements to Siri. I’d love to see a price drop as well (though it does pack a lot into a small space for the money).&lt;/p&gt;

&lt;p&gt;Basically, I don’t want to buy a HomePod based on future promises/expectations. Things I expect from HomePod may not be in Apple’s plan, and for that I don’t want to assume that will change. Instead, I’ll wait to see how HomePod plays out. I’d imagine like most of Apple’s products, the first generation keeps things very simple, while the second or third generation (be it software or hardware) tends to really sell the product. HomePod’s hardware shouldn’t need too many refreshes that often, so hopefully we’ll see some big software updates before too long to get me to try it again.&lt;/p&gt;</content><author><name>Aaron Dippner</name></author><summary type="html">I purchased the HomePod nearly two weeks ago, and today it went back to Apple. I still stand by a lot of what I said in my previous article. As a speaker, HomePod is fantastic device not just for sound, but for ease of use too. It’s going to be hard to find something that has such omni-directional, quality sound. The size of the HomePod is particularly impressive for what all it accomplishes. Best of all, the complete ease of use (especially compared to the traditional amp and speaker setup that may scare some users away) makes it as painless as possible.</summary></entry></feed>